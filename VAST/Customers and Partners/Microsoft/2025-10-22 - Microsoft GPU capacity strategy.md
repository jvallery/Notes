---
type: "customer"
title: "Microsoft GPU capacity strategy"
date: "2025-10-22"
account: "Microsoft"
participants: ["Jason Vallery", "Rosanne Kincaid–Smith"]
source: "transcript"
source_ref: "Inbox/_archive/2025-10-22/2025-10-22 - Jason shared candid guidance on Microsoft’s approach to GPU capacity preference.md"
tags:
  - "type/customer"
  - "account/microsoft"
  - "generated"
---

# Microsoft GPU capacity strategy

**Date**: 2025-10-22
**Account**: [[Microsoft]]
**Attendees**: Jason Vallery, Rosanne Kincaid–Smith

## Summary

Jason shared Microsoft’s current approach to GPU capacity: preference for in-house data center builds with selective neo-cloud partnerships to hedge capacity gaps and shift GPU capex risk off Microsoft’s balance sheet. They discussed lease pullbacks driven by finance/balance-sheet risk management, uncertainty in 5-year GPU depreciation amid rapid accelerator roadmaps, and how fiber proximity to hyperscaler hero regions determines whether sites can support training vs inference. Rosanne described Dhammak’s rapid data center/GPU cloud buildout and intent to secure Microsoft as an anchor tenant, with Lior facilitating an intro to Anand at Microsoft.
## Key Information
- Jason is on day 3 at VAST, leading product management focused on hybrid scalers and frontier model builders.
- Rosanne is based in Dubai and recently joined Dhammak Group to build a vertically integrated GPU/cloud platform.
- Dhammak acquired nearly 5 GW of power and land and is targeting ~500 MW capacity online by early next year with multi-gigawatt expansion across Asia, US, and Europe.
- Dhammak is pursuing a marquee/anchor tenant similar to Microsoft’s partnerships with neo-clouds (e.g., CoreWeave).
- Lior is facilitating a conversation with Anand at Microsoft.
- Microsoft prefers in-house builds but uses neo-clouds to hedge capacity gaps and shift GPU capex risk to partners/investors.
- Microsoft lease pullbacks were driven by CFO/balance-sheet risk management; some leases later resumed as demand materialized.
- GPU asset life/depreciation modeled at ~5 years is uncertain given rapid accelerator roadmaps (e.g., H100 to GB200) and competing accelerators (TPUs/ASICs).
- Workload placement depends on network: remote power-rich sites without major fiber are better for inference than training; fiber proximity to hyperscaler hero regions is key.
- Data gravity is shifting as compute chases power; storage must move data to compute; VAST positions its global data namespace for distributed compute.

---

*Source: [[Inbox/_archive/2025-10-22/2025-10-22 - Jason shared candid guidance on Microsoft’s approach to GPU capacity preference.md|2025-10-22 - Jason shared candid guidance on Microsoft’s approach to GPU capacity preference]]*

## Related

- [[CoreWeave]]
- [[Oracle]]
- [[Google]]
- [[Amazon]]
- [[Rosanne Kincaid–Smith]]
- [[Jason Vallery]]
- [[Lior Genzel]]
- [[Sam Altman]]
- [[Amy Hood]]
