---
type: "customer"
title: "Microsoft AI capacity and VAST"
date: "2025-11-12"
account: "Microsoft"
participants: []
source: "transcript"
source_ref: "Inbox/_archive/2025-11-12/2025-11-12 - Announcements.md"
tags:
  - "type/customer"
  - "account/microsoft"
  - "generated"
---

# Microsoft AI capacity and VAST

**Date**: 2025-11-12
**Account**: [[Microsoft]]
**Attendees**: 

## Summary

Notes summarize SemiAnalysis and Microsoft disclosures indicating Microsoft’s “big pause” has ended and they are scrambling for near-term AI capacity via self-build, leases, and neoclouds, with Azure Foundry positioned as a token/API monetization engine. The Microsoft–OpenAI partnership terms (Azure API exclusivity continues; IP rights extended to 2032; research IP access ends by AGI panel decision or 2030; OpenAI commits $250B Azure spend; no ROFR) suggest both locked-in Azure demand and more operational flexibility, creating positioning opportunities for VAST across Azure overflow, multi-provider OpenAI builds, and Foundry/post-training data-plane needs.
## Key Information
- Microsoft’s “big pause” is over; they are seeking near-term capacity across self-build, leases, and neoclouds.
- Microsoft monetization thesis emphasizes Tokens/API over IaaS; Azure Foundry described as a “token factory.”
- Accelerator dependencies: Nvidia remains primary; MAIA lags; Microsoft may use OpenAI’s ASIC.
- Microsoft–OpenAI Oct 28 agreement (as summarized): Azure API exclusivity continues; Microsoft IP rights extended to 2032; research IP access ends by AGI panel decision or 2030; OpenAI to purchase $250B+ of Azure services; no right-of-first-refusal for Microsoft; both can independently pursue AGI.
- SemiAnalysis view: post-training compute is ramping and latency-insensitive, enabling remote DC placement; GPU economic life extends beyond 2–3 years, implying long-lived clusters with continual data growth (checkpoints, logs, evals, datasets).
- VAST positioning suggested: fastest route to usable capacity for OpenAI/Foundry tenants; portable consistent data fabric across Azure/Oracle/CoreWeave and future OpenAI ASIC pods; Foundry-ready data plane (caches, RAG corpora, logs/telemetry, retention tiers).
- Guidance suggested: lean into neocloud co-sells for Azure overflow; pitch “accelerator-proof” storage across changing GPU/ASIC mix; bundle a Foundry-specific offer (“Token Plane for Azure Foundry”) and benchmark token/$/TB.

---

*Source: [[Inbox/_archive/2025-11-12/2025-11-12 - Announcements.md|2025-11-12 - Announcements]]*

## Related

- [[OpenAI]]
- [[Oracle]]
- [[CoreWeave]]
- [[NVIDIA]]
- [[Fairwater]]
