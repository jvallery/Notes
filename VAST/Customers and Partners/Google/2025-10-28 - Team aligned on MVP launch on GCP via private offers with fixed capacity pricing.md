---
type: "group-meeting"
created: { { DATE } }
title: "20251028 0800 Parallels Transcription"
participants: [{ { PARTICIPANTS } }]
ai_extracted: true
transcript_path: "00 Inbox/Transcripts/20251028 0800 Parallels Transcription.txt"
tags: [meeting, group]
---

# 20251028 0800 Parallels Transcription

**Date:** 2025-10-28  
**Participants:** Eirikur Hrafnsson, Helen Protopapas, Jason Ainsworth, Jonsi Stefansson, Lihi Rotchild, Lior Genzel, Timocin Pervane, Tomer Hagay, Jason Valeri, Yancey

## Summary

Team aligned on MVP launch on GCP via private offers with fixed capacity pricing transacted through the marketplace using Tackle.io integrated with Salesforce. Polaris will manage entitlement, call-home, and usage; no BYOL for MVP. Overage handling and EULA language need finalization, and finance will embed in Tackle implementation and set up billing, reconciliation, and reporting controls ahead of first transactions targeted for Novâ€“Dec.

## Key facts learned

- MVP pricing: $0.07/GB capacity; fixed term, fixed price via GCP Marketplace
- All transactions to go through marketplaces; no BYOL in MVP
- Private offers generated via Tackle.io; synced with Salesforce opportunities
- Polaris is the source of truth for entitlements, usage, and metering
- Secure boot + call-home to Polaris; no license keys; entitlements enforced via tokens
- Considering 10% overage allowance; overage to be charged at list PAYGO if supported
- GCP Marketplace lacks native overage-at-PAYGO; Tackle may provide a workaround
- Need EULA language to cover overage billing in marketplace offers
- Customer alert exists on exceeding limits; internal CS/sales alerting not yet in place
- Hybrid on-prem/cloud licensing presents complex rev rec; conversion model may be needed later
- Multi-cloud technically possible; hyperscalers may resist cross-cloud messaging
- First GCP transactions targeted for Novâ€“Dec; approach to replicate to AWS/Azure thereafter
- Finance will not have separate cloud P&L; cloud metrics reported within overall P&L
- Consumption/usage-based SaaS metrics and forecasting model to be defined before SaaS launch

## Outcomes

- Confirmed MVP scope: private offers only, fixed capacity pricing, no BYOL
- Agreed to use Tackle.io as middleware for marketplace offers tied to Salesforce
- Polaris confirmed as metering/entitlement source and integration hub
- Agreement to allow overage conceptually and pursue PAYGO list pricing via Tackle workaround
- Finance to participate in Tackle implementation to shape billing, reporting, and controls
- Plan to set up a deeper session on billing/invoicing, payments, and reconciliation flows
- Invite extended to include finance (Jason Valeri) in Tackle meetings
- Targeted first GCP deal in Novâ€“Dec; then replicate to AWS/Azure

## Decisions

- Transact exclusively through cloud marketplaces for MVP (no BYOL)
- Use Tackle.io to generate and manage private offers integrated with Salesforce
- MVP pricing based on fixed capacity at $0.07/GB
- Polaris will manage entitlement, call-home registration, and usage reporting

## Action items

- [x] Review and draft marketplace EULA language to enable overage billing at list PAYGO via Tackle workaround @Myself â« âœ… 2025-11-08
- [x] Invite finance (Jason Valeri) to Tackle kickoff and ongoing implementation meetings @Eirikur Hrafnsson â« ðŸ“… 2025-10-29 âœ… 2025-11-08
- [x] Confirm with Tackle.io the feasibility and configuration for overage handling and pricing on GCP @Eirikur Hrafnsson â« âœ… 2025-11-08
- [x] Implement automation to create Uplink organization endpoints from Salesforce metadata for call-home registration @Polaris team â« âœ… 2025-11-08
- [x] Design and implement internal alerting for CS/sales when customers approach or exceed entitlement @Polaris team â« âœ… 2025-11-08
- [x] Define overage policy (thresholds, grace, pricing) and reflect in offer terms and EULA @Tomer Hagay â« âœ… 2025-11-08
- [x] Set up finance processes for marketplace billing, receivables reconciliation, and revenue recognition for fixed capacity and overages @Finance â« âœ… 2025-11-08
- [x] Provide finance with access to GCP marketplace reporting/portal and sample/mock payout reports @Eirikur Hrafnsson ðŸ”¼ âœ… 2025-11-08
- [x] Schedule and run a detailed walkthrough of the Tackle-to-Salesforce private offer flow and data sync @Eirikur Hrafnsson ðŸ”¼ âœ… 2025-11-08
- [x] Define VAST units of measurement for compute and capacity for future pricing model @Tomer Hagay ðŸ”¼ âœ… 2025-11-08
- [x] Plan for cloud customer success coverage to drive expansion and manage entitlement/usage @Lihi Rotchild ðŸ”¼ âœ… 2025-11-08
- [x] Prepare pipeline visibility for expected first GCP transactions and timelines @Lior Genzel ðŸ”¼ âœ… 2025-11-08

## Follow-ups

- [x] Validate GCP overage-at-PAYGO approach and confirm Tackle configuration path @Jason Valeri â« âœ… 2025-11-08
- [x] Confirm internal alerting and dashboards for entitlement usage in Polaris/Uplink @Polaris team â« âœ… 2025-11-08
- [x] Set session to define billing, invoicing, payout cadence, and reconciliation across Polaris, Tackle, and GCP @Finance â« âœ… 2025-11-08
- [x] Decide whether to permit automatic expansion beyond entitlement or require account approval @Product ðŸ”¼ âœ… 2025-11-08
- [x] Outline rev rec approach for future hybrid conversion model (on-prem â†” cloud) @Finance ðŸ”¼ âœ… 2025-11-08
- [x] Assess feasibility and policy for multi-cloud pooling and metadata roll-up to Salesforce @Polaris team ðŸ”¼ âœ… 2025-11-08

## Risks

- GCP Marketplace limitations on overage pricing may delay or complicate billing
- Missing automation for Uplink org creation from Salesforce data
- Lack of internal usage/overage alerting for CS/sales may hinder upsell and compliance
- Hybrid on-prem/cloud conversion creates complex rev rec and operational processes
- Reconciliation and reporting processes are not yet in place ahead of first transactions
- Potential need for dedicated cloud customer success resources not yet staffed
- Pricing disparity across customers could persist without unit-based model
- Multi-cloud positioning may conflict with hyperscaler expectations

## Open questions

- Can Tackle fully support GCP overage billing at list PAYGO despite marketplace limitations?
- What exact EULA language is required to enforce overage billing terms in marketplace offers?
- Will expansion beyond entitlement be auto-permitted with overage or require account manager action?
- What is the final overage threshold (e.g., 10%) and how will it be communicated and enforced?
- What is the payout cadence and reporting detail from GCP, and how will it be accessed?
- When will automation for Uplink org creation from Salesforce be ready?
- How will internal CS/sales see real-time usage and trends (Polaris vs Uplink dashboards)?
- What is the chosen approach for hybrid on-prem/cloud licensing conversion and rev rec?
- Will we standardize on a VAST unit model across cloud and on-prem, and when?
- How will multi-cloud pooling be handled from pricing, entitlement, and reporting perspectives?

---

## Transcript (auto)

```text
[00:00:00.00]   RemoteWe've spent a lot of time together recently. This one I think is much more tactical. It's, hey, we're launching in a couple of weeks, the kind of back end. Are we ready to do that? So, we just need Jason to join. Silence >> Are you waiting for it, Timo? >> Jason Ainsworth, he's the one who set up this call, so it's -- there's sort of like two lenses here. One, the review that we had set up coming out of the AMP kickoff was -- for the whole of FY27, so thinking about what does the business look like in FY27, how do we support it, et cetera, and then there's also, we're launching in a couple of weeks, and so I think this was Jason realizing we're launching in a couple of weeks, we need to make sure the back. at the end is ready to support the launch and so much more tactical as opposed to, you know, what's the FYI twenty years ago and so much more. We're paying guys. Hey, I'm sorry about that. Hello, just wrapping up. discussions. Yes, thanks, Tomer. Yancey, Leo, I appreciate you guys taking the time to meet with us. I know we're imminently looking to launch in GCP, at least on the private offer side. I wanted to spend a little bit of time going through a little bit more tactically, kind of from an accounting and finance perspective, some of the elements of that, so that we can to make sure we're ready to support it and actually have the ability to quantify, accumulate, and report out, and if there's any kind of open elements that we need to step in and support in order to get some of this stuff operationalized and up and running. So I prepared a list that we can kind of walk through. from a more tactical standpoint, some of which I think we've already addressed in some of the AOP hyperscaler meetings, but maybe more at a higher level, and so, hoping we can focus this discussion really on GCP, given that that's the most urgent, or at least the most relevant of the hyperscalers perspective today, and then, you know, we obviously can kind of replicate this or build a process to, to, to be able to do this, you know, on a hyperscaler by hyperscaler basis as we go forward, kind of effectively develop a playbook as we want to onboard new partners in that respect. So I also know that there's gonna be a phase rollout starting with private offers eventually, actually moving to public offers on the marketplace and then hopefully in the relatively not too distant future being able to do our own hosted solution where we kind of have a full-blown SaaS model, and so some of the new. going to change not only from an accounting and finance perspective, but from an infrastructure perspective, and so we kind of want to stay with you guys along that journey, because the most complex for us is going to be the full-blown SaaS model for various reasons, and we can have those conversations when the time is right. But I'm going to share a list that we can kind of utilize as a guide to guide our conversation. I think for certainly for Leahy on this call and for myself, you know, at some level where, you know, we haven't been necessarily as involved in some of the, you know, the planning. and phased rollout conversations, if we could get just a quick overview of like, you know, what's relevant over the next three to six months in terms of what are we offering and how are we offering it and kind of how will that ultimately, you know, transact from a customer perspective. because in our last conversation I heard maybe we do a private offer it would include the price of the potential on-prem solution but somehow that would get transacted through the marketplace to consume the customer's you know commitments with with GCP etc etc. Just kind of trying to wrap my head around exactly how this is going. going to work from a customer perspective, and then we can get into some of the more nuanced transactional questions, but just trying to kind of level set in terms of what we're looking to roll out here over the next few weeks. Yeah, absolutely. I mean, what we are rolling out is the MVP and I think we are all alike. Lee or Jason, Eiki, you know, Tomer and Wolfie that we start with pure capacity pricing which the list price is 7 and then we are going to be working 7 cents a gigabyte. We are going to be working on creating, and Jason, thank you for coming. great driver, Jason Valeri. We're going to be working on trying to figure out like a vast unit of measurement, both for CPU with Tomer, of course, and with, you know, the vast unit of measurement for compute and for the data nodes. for the capacity. So we're going to be just actively working with Tomer and team until we launch this on-prem and how do we change that? Do we change that for the private offer or do we change that for the public offer? And of course going forward for the full-blown multi-tenant SaaS we are going to be utilizing the new pricing model. Everything has to be transacted through the marketplace. So we don't want to do any like BYOL or bring your own licenses. Because ultimately this will help us in our relationship with the hyperscaler, this will push us further up. the partner status and we will get more marketing dollars and like MDFs, marketing and development funds, based on how much we are transacting through the hyperscalers, and the end customer? From who? From Google? Yeah, in the Google marketplace. course in the Azure marketplace and the AWS marketplace and the Oracle marketplace I mean the average like it varies quite differently based on our partner status like the the rev share is for somewhere between one and a half to three and a half percent That's what the marketplace takes. So, you know, that that's the MVP. Okay, so I think, I think we're, we're, so that's helpful, I appreciate that. I guess with that, then maybe we can just get a little bit more tactical and we can kind of go through some very specific questions. So, from a, from a. contracting structure, I know we have a contract with GCP in terms of our utilization of the offering of our software on their marketplace. How will we transact with the end customer from a T's and C's perspective? Or do we at all? the contract and all the entitlements are built into the marketplace offering. So, this is basically, we own the contract with the customer, but the contract resides within, is part of the marketplace. When we do, that's one of the reasons why we're doing like tackle.io, which actually is an integration layer between Salesforce and as soon as somebody creates a quote in Salesforce, it will automatically create a private offer that gets distributed through the Google marketplace, and the customer either declines or approves the quote, and then they will get sent a link in order to be able to begin the deployment, the automatic deployment of VAST. What is the starting point? The Tackle.io or the Salesforce? Like you create a quote where? So that's what we are working with TACL, whether they actually do it through TACL.io or they actually do it directly through Salesforce, and TACL actually becomes that middleware to generate the private offer. So Eike, you were in the last TACL meeting, right? And we have another one kickoff tomorrow. So the way I understand it is that you create a private offer through TACO that, that updates the opportunity in Salesforce. There is metadata that's needed to be set in Salesforce the size of the deal, both the dollar amount and the allocated terabytes to start with for the MVP. Because the next step is that the customer gets an email with the private offer link. This private offer link It goes to the Google portal so whoever accepts the offer needs to have the rights to to approve an offer in the Google marketplace and this goes for all of the like we're unifying this through tackle for all of the hyperscalers with the exception of OCI for now. because they don't support OCI but they support AWS TCP and and Azure. So the next step is that the customer goes in, sees the private offer and approves it. Once they approve it, essentially the subscription starts. That means it's up. updated in TACOL, Polaris gets notified. There is a middle step there where we ask for additional information, but that's not really concerned here on the pricing or sales or anything like that. It's more for us to understand what has been sold on the Polaris side, and then this updates Salesforce, this updates Packo and it notifies Polaris of a stopped or change of a subscription. So from there on, we can do things like checking for entitlement, balancing, balancing like the cloud entitlement. versus on-prem entitlement if we add that capability and so forth. Then there are capabilities to add to this, so you could add, for example, an addendum uh do the private offer or you could cancel the previous private offer and create new one. This is all handled through TACL. So TACL becomes the touch point for our offers or anything that transacts through the marketplaces, and this also opens up the capability to you know, allow partners. even to sell through Tackle, and it solves the problem of like we don't have to, we don't have to allow individual sales people access into our Google project or our AWS account, which they would otherwise need to create private offers. Have you looked at, I mean, I'm sure you have, but what happens next, right? Because we need to issue a license, we need to assign a PSNT for that system, so it could be identified and recognized and call home and all that. Are you taking care of all these? Yeah. So we don't use any... any type of license. What we do is we have a secure boot process. It won't go into maybe the details of that but essentially there's a call home function when the cluster comes out that calls home to Polaris. Polaris is the source of truth for entitlements. Basically the license, what are you allowed to create, and during the bootstrapping of the cluster, we will register it to uplink. So I have an ongoing query in the Polaris, project Polaris. Slack channel. We're trying to find out how Uplink, you know what data Uplink needs in Salesforce to be able to generate the organization endpoint for Uplink. So that's that's a missing feature right now, but once that is done if there's an automation that can be done from Salesforce to uplink then all clusters will automatically be registered with the call home function for for monitoring and operations. Yeah right now it's a current gap because we don't have PSNTs assigned and we disabled the license mechanism so yeah you know we're not because we're not enforcing anyway so yeah so there's no need for like a license step really in here because you won't be able to create a valid cluster there's no IP on the images that run like the the only thing basically on the images that when they run is an agent for Polaris and there's some installations script or partial installation script, and when the Polaris agent calls home, that's when, you know, we check for the, you know, do we have an active subscription? Are you allowed to have the entitlement to create this size of cluster? All of those things are checked, and then we give you access to the version or that we want the automation to install rather so that's kind of so it's all protected by a token that gets gets registered to Polaris and assigned to the cluster and that has the entitlements. a much improved version of the MCM. - Yeah, yes, absolutely. - Hopefully. I think so, I agree. It's just been a long discussion and decision to how we do this. - Okay. Super helpful overview. There may be a point, Eiki, where we'll actually want to like, you know, through some examples of how this will work and tackle and kind of see, you know, systematically what's happening and what data is available and kind of how we think about how it reconciles between the systems, etc. But that's not the purpose of today's call, so I appreciate that. I mean we have to go and teach the our. Salesforce how to do these private offers, and the reason why we're going this route is otherwise we would actually have to have them log into and give them access to a marketplace access where they would have to figure it out themselves and it makes it very complex. So we're simplifying this in order for the Salesforce to be able to churn out quotes and private offers. That makes a lot of sense if we can manage a single system versus having unfettered access to the hyperscaler accounts. In this private offer rollout that we're starting with, my understanding, these are fixed price capacity contracts. versus some sort of consumption-based or usage-based mechanisms, can you kind of walk through how it either sits alongside an on-prem existing contract, an on-prem kind of net new contract, or on a standalone basis, kind of how we should be thinking about it? this? I mean, the list price for capacity is identical to what we are offering on-prem today, and of course, going forward with Tomer and Wolfie changing the pricing model, we will... lot up to that going forward. But, I mean, to be honest, right now, like we are, we are still debating whether we can actually have this correlation between on-prem and the cloud. actually actively debating that back and forth right now on an email thread, like is it actually to be expected from end customers? So that's one of the reasons why we're discussing it back and forth. But ultimately with the public offer and certainly with the full-blown multi-tenant SaaS we will have PAYGO and that will you know then you're basically creating new entitlements that are not capacity-based or allocated capacity-based or usable capacity-based it's just going to be metered, and so on the private offer effectively we're saying hey customer you on a, you know, a 300 terabyte. - 300 terabytes, yeah, precisely. - And so it's just a dedicated system that is available for their use, you know, throughout the duration of the contract, just like it would be if they had hardware sitting in their data center. - Yes, absolutely, and the tradition is to allow maybe 10% overage and then charge for it and then ask. them to re-up their entitlement because we don't want to stifle the growth. So we are very likely going to allow somewhere between like, Aki, what we did, did we discuss 10% overage? Because, you know, and how do we charge that? Yeah, I mean we could, so right now, the way that you expand is manual like you would go into Polaris and you would expand so I think we need to bring it up there or notify at least the customer that you know this expansion will be overage unless you request unless you request a you know a new private option. offer for the expansion. So I think it's a decision point for us, do we allow expansion beyond the limits of this? We can handle it in the marketplace offering, it just means, like JÃ³nsi is saying, it will be charged with an overage. or do we want to push it towards. you know, the account manager to create, in some cases, like emergency cases, for example, they might just have to expand and cannot wait for this whole process, and the other thing is, here's where we have to take into account. customer success for the cloud. Because ultimately in the cloud, with great customer success, you will get great upsell and expansion. So that is part of what we have to take into account on on our sort of AOP planning is we need. potentially dedicated cloud customer success people. Yeah, and I would say that's part of the subject of Friday's AOP call is on the support customer success side. I would say to just as just as a quick, like input, I think, broadly speaking, I think, Aki, what you said makes sense, like you don't want to have customers run into a it just stops. You go beyond, but then you get a flag that says, "Hey, you're X percent over, or you're coming within X percent of this." It maybe comes like a gray area also between the functionality of Polaris and the functionality of Uplink. So I'm unclear on whether sales or account folks, or customer success folks, if they have access to like actual usage, trending, like for a customer, because I think it's highly useful for us, especially on the customer success side, you know, understanding how quickly. customers are using the space or how quickly they are adopting the features and things like that. Those are the type of features or type of capabilities we could or statistics that we could push to tackle for example or make it available through the admin interface or Polaris whatever how we do that or maybe that's already existing. in Uplink for our salespeople to know. Yeah, I would say I don't believe it exists today. It's been the subject of multiple discussions. So, you know, the notion of even just the very simple of, "Hey, how much capacity is the customer using? Are they coming up to their limit? Okay, go make that call salesperson." Yeah, exactly. I don't believe that exists today. We could... easily do that, or if that doesn't exist we could pretty easily do that. My understanding is we don't necessarily have a mechanism, or if we do have a mechanism we don't have like an actual motion to enforce licensing requirements, you know, at a fine-tuned level, so customizing... could be, you know, using more capacity than they're licensed for and we don't have a trigger that says now we need to go have that conversation that says they need to come by new licenses. We don't. Yeah but I mean we definitely if it doesn't sure sounds like it doesn't exist in uplink we will definitely need to have that in a task board in Polaris. then because ultimately I want customer success to be able to call on the customer saying hey Mr. customer you are continuously at that 10% overage that you're allowed to have you need to or you need to re-adopt your entitlements in the private offer. There is currently a flag or a larynx that the customer is getting when he's exceeding the limit, the license limit. The customer gets an alert, it's not stopping him from using it, but he gets an alert. Yeah, I want to have it vice versa, I want us to get the notification, I mean, or both. because I mean ultimately like because we don't have like to Tomer's point don't have that on-premise licensing server that is actually constantly checking which Polaris in a lot of sense actually helps with you know there's nothing that stops the customer to deploy vast on other hardware without paying vast and I don't want that in the cloud. It's more easily controllable in the cloud because you can't just like that what the customer could do they could go in and we control basically the cluster through through these managed instance groups. So they could go in there, they could say like out at a VM. That means like a VM comes up, and the sort of auto register process would start. But it would be declined. Because they don't have entitlements to enlarge. Yeah, like it would start the process, though it's a normal process, and they would go through if they have entitlement. But then we we already know to to us, though, on the on the billing side of things. It doesn't matter if they're using half of their entitlement or not, we're always charging them for the full entitlement. Yeah, so they can play around within within We could decide that you can always add, you know, one host, two hosts or whatever, but that is covered by overage, and that's a conversation that we have to take into account with how we do that with TACO.

[00:28:01.51]  Jason ValleryYeah, pricing. So we're talking about the way you'd likely want this to work is the reservations cover. the fixed amount that you've committed to and then when you have an overage that would just be charged at pay-go pricing so you'd have some sort of monthly accounting that's

[00:28:26.76]   RemoteDischarged. Yeah that is what we would like it to be. I'm not 100% sure that's how it works. So we, Jason, we asked for that for the Google marketing team that Let's say somebody buys a petabyte and we sell it or 100 petabytes and we're selling it at two cents a gigabyte licensing-wise, and if it goes to 110, those 10 petabytes will be charged. seven dollars list price as the payco price, seven cents, and I know you can do it in AWS and Azure, but Google said, "Oh, we can't do that." - But I think Tackle, they said they might have a solution for that. It's one of the reasons why we... started talking to tackle in the first place, because the GCP marketplace is just not as advanced as the other ones. Well, and it also forces the customer to then look at the cost they just paid for the overage, and they say, "All right, we should go commit to a higher level of capacity so we can get it back at the two cents." Yeah, exactly. I think we should make it easy for expand without with the least amount of blocking them. But I agree like that should be probably the default that we probably we might need to have that somehow mentioned in the EU law or something, you know, say, I mean, they're, they're agreeing to a certain contract and in the marketplace, we need to specifically say any type of overages, you know, charge that XTOL or not? But, I mean, Jason, Valeri, this is what we have to take into account as well. I mean, it has to go into the end-user license agreement in the marketplace. If we are going to go down that path and if TACL can actually help us. with charging list price for overages, and it's also an incentive for the customer to re-up their private offer. Exactly, yeah. Okay. Jason Valeri, can you take that ball? the side of it and see what we need to say there yeah see if we can we do need to have to like if we are if Tackle.io is able to fix this even though the marketplace doesn't offer it what how do we need to or what do we need to say in the end-users agreement for the product

[00:31:09.12]  Jason ValleryI'll take a look at it. I'll reach out to you offline, because I'm not super familiar with Tackle, I haven't worked with it before, so it's a new area for me, but yeah, I'll take a look at it.

[00:31:14.97]   RemoteOkay, thank you. Yeah, and Eiki, let's invite Jason to the Tackle meetings. Yeah, tomorrow. Okay. Yeah. Okay, let me forward that kickoff call. The next question I have on here is, I've heard this notion of customers having the ability to use VaST on-prem or in the cloud and they can kind of switch back and forth or something to that effect, some sort of, you know, kind of the hybrid slash burst. concept in like practically speaking how exactly does that work is it just is it's a contract with fixed capacity part of it's on-prem part of it's in the cloud and like how exactly does this work um in terms of being able to switch back and forth or run them alongside each other? This is, of course, the sort of dream scenario that we were talking about yesterday or Friday. I'm getting all the days mixed. Yeah, but it's a fixed capacity, like you're saying. Let's say a customer buys, and here's the dilemma with this, and I've been giving it quite a bit of thought. do we, you know, let's say the customer is on-prem and none of the deals currently has gone through the marketplaces. This would basically require us to do a BYOL and not transact through the marketplace, which is I am not a fan of, but in order to be able to build the business up faster, like from a finance perspective, because we are all gold and have gold on cloud, let's say a customer buys this blended offering or hybrid offer, and we allow... own license. How is the revenue recognition going to be from finance perspective? That's a complicated one that I need to spend some time on because it's two completely different models. One stand ready recognized over time and the other one's delivered up front recognized you know based on value allocation. and having a right to switch between the two, I need to spend some time on.

[00:33:53.14]  Jason ValleryI mean, what I've seen before is some sort of conversion process where you allow the flexibility, but the customer has to request a licensed conversion from type A to type B, so it is not completely portable back and forth, and then you change the recognition models, allocations in terms of how you know the value of the on-prem license equates to a pricing model

[00:34:13.16]   RemoteThat's different in the cloud. That's correct and you have to have there's a number of assumptions that go into that on day one in order to effectively estimate or have a determination of what we actually think the customer is going to do based on what we've seen. to do before and you have to essentially attempt to parse the value between those various scenarios and then account for them as those scenarios unfold. But it's not a super like automatable type of a model. So we'd need to spend some time on it to figure out how we operationalize it Because, I mean, in that scenario, wouldn't the customer have to give a projection on how much he's actually going to be using in the cloud, and that gets transacted through the marketplace, and the other one, like, that then... it sort of breaks the dream state model, you know, where you can actually just have like a single offering of 200 petabytes and you decide completely how you deploy it, whether it's on-prem or in the cloud. Because ultimately, like I can't see any other way then to allow BYOL in order to achieve that.

[00:35:43.23]  Jason ValleryI mean I think the only way to get to what you're describing, Jansi, is if we forced all customers to go through marketplace cloud pricing model on-prem or not, and then you fundamentally just make the way it's sold on-prem, and you convert existing licensing

[00:35:56.60]   RemoteInto that model. That's a huge leap. That's where I was going to go because if there's whatever, if 80% of it is bought via an on-prem license and then 20% is bought via the marketplace, when they want to use some of that 80%, what happens to the marketplace fee as well? Seems like you'd have to shift to all marketplace. would be pretty major. Yeah and not all, sorry. Like how do you offer it to the customers? Do you say you can shift licenses between both environments or like what is our offer like is that? I mean what the customer expects in those cases and we did that in previous life for the self-managed CVO or Cloud Volumes on top. Okay, one idea here. So when... I have to validate this with Taco though. When we report... Okay, so when we are reporting usage... we're always basically reporting the same. We're just taking the payment schedule, what's defined in the private offer or the pricing, and we're dividing it by the number of hours this month, and we're basically providing like a usage reporting every hour, and the only thing this controls is... what is charged so we're always trying to match the fixed price because it's a fixed price plus overage all the offers will look like that and so we're basically just always reporting the same thing there's nothing that says that we couldn't in Polaris either reading it from Salesforce or just inputting it manually for each customer in the admin part of Polaris. There's nothing saying that we couldn't say that this customer is going to use, you know, 500 terabytes of the one petabyte of their entitlement, but add a weight to it, meaning that you know, it actually is represented as 600, and then you have only 400 left. Do you understand? Do you see what I'm saying? Because it's a fixed price, it's basically a contractual, it's a contractual offer that says like, you're buying this, whatever. Like, we could always play within that pricing, you know, the dollar amount for the cloud terabyte versus the dollar amount for the on-prem terabyte, and by doing it that way, we don't have to scale it the same way. Like, we don't have to say one terabyte in cloud costs the same as one terabyte on-prem. if we want to do it I'm just saying like we could we could play with that so the only thing that changes then for us on the Polaris side is that if somebody inputs a you know an on-prem terabyte usage or we get it from Salesforce or however we do it then we're scaling what's available to the cloud based on pricing on prem versus cloud.

[00:39:26.03]  Jason ValleryThis is what's important about it. One of the things that I was proposing in that thread was if we use a vast data unit as the unit of transaction, you apply a multiplier depending on the different environments or the different tiers and you can certainly apply it.

[00:39:39.84]   RemoteOkay, yeah.

[00:39:40.76]  Jason Vallery...prem versus...

[00:39:41.49]   RemoteYeah, absolutely.

[00:39:42.57]  Jason ValleryThat solves that problem.

[00:39:43.82]   RemoteOkay. would solve it but that would only solve it if all these transactions would go through the marketplace. This would not solve for example let's say xai wants to go to Google for some specific workloads already has an existing agreement it could not be done on vast paper. It would go through the marketplace, if we want to solve it that way, and in many cases, the marketplace teams are not that willing to sell something that is not doesn't get deployed on.

[00:40:32.47]  Jason Valleryon on the actual clouds. Is it a forcing function though for those customers who are on a legacy pricing model when they want to go to the cloud you open the conversation up and then sell them on the new pricing model so that we can take XAI's business to the cloud with a structure that aligns with how we're selling it to the rest of

[00:40:48.98]   RemoteOur customers? Yeah, absolutely. Absolutely. be a very good strategy going forward, you know, and use that as a vehicle to, you know, up-level our existing customer base to the new pricing model. That part would be a nice benefit of it. One question, just to understand, I don't know how much of an issue this is, but what happens if there's a customer who wants to use vast on two clouds so they've got like on-prem and then they have some Google some AWS yeah technically nothing like this technically nothing stopping us from doing it we're using the SAS product offering which means to the to the a hyperscaler, it means that the service can either be provided on Google or somewhere else. I wouldn't talk loudly about it because the hyperscalers, they don't like it, but there's nothing stopping us from doing that. I think it would be hugely beneficial for us. I don't know. I agree with that, Josip. customers they might have a huge commit on one cloud provider and not the other.

[00:42:04.12]  Jason ValleryWell I'm curious about the idea of pooling as well, so if you were to say by arbitrarily a thousand petabytes of capacity and they have that spread among providers and the ability for them to leverage that as one commitment with us, like would Polaris support that kind of model?

[00:42:23.46]   RemoteYeah yes absolutely we're gifted that but it from a technical perspective it does mean that however we register these usages they need to somehow trickle up to probably salesforce so that we have a unified source of truth for them yeah the metadata on what is used where. I actually have a question from a financial perspective. How are we going to be reporting on cloud? Are we going to be reporting on revenue? Are we going to be reporting on annual or ARR? What's the difference? So we're not going to have a separate P&L. It's going to be rolled into our vast wide P&L, and then in the reporting will show additional metrics from a cloud lens, which would be, you know, just that, I mean, we're understanding the model now but would be the full set of metrics so you know bookings. - Okay. - Part of the extent, I mean card kind of makes less sense here 'cause it's should be pretty instant, but live ARR revenue and so on.

[00:43:38.55]  Jason Vallery- So to clarify, a three year commitment, are you recognizing the full three year revenue up front or is that spread out over the 37 months? And then how does that align with if their pay go and they're, we're getting it on a monthly basis?

[00:43:53.50]   RemoteSo the way it works today is a three-year booking. I'll just simplify it. I can, Jason, actually, we should set up time. I can take you through how we report. So at a simple level, there's three-year booking. So we recognize the booking amount, so the full total contract value over three years in the period. which it's booked and then or we have something called CAR which is basically the annualized portion of that so one year of that and then we have something called live ARR which is when that goes live in the data center that becomes live ARR which is the annualized again annualized revenue and then there's revenue itself which is actually actually, you know, the recognized revenue within the period from when it goes live, and for consumption, we don't have that model today, and so something we need to work through as we work through these calls. Yeah. I mean, I think these fixed capacity, you know, fixed term contracts, we'll just. roll into our existing metrics the way that our on-prem metrics exist today, because they have this similar behavior. The consumption-based, usage-based, you know, full-blown SaaS model, kind of on-demand pay-go model is a whole nother piece, and so we're gonna have to, yeah, we're gonna have to build out the right metrics, build out forecasting. capabilities, so on and so forth. It's just a completely different business model than what we have today. Different animal. Yeah, absolutely, and I think we need to get going on that one to have it formulated before we go live with the full-blown SaaS. Because I mean, cloud is supposed and it's going to go up and down and in many cases, especially with companies that have not been doing cloud before, they start panicking and viewing that as churn when it's not churn when it's basically perfectly normal behavior in the cloud.

[00:46:02.83]  Jason ValleryYeah, or data will move from one bucket to another, which have a different price.

[00:46:06.91]   RemoteYeah. drops but data volume grows and it's just yeah absolutely yeah yeah there's there's a lot of thinking and and growing that we're gonna have to do as it relates to blending these two business models and eventually moving to a full-blown size as well sitting alongside a traditional on-prem software business um so is it a true statement though today like when we roll out in a few weeks, everything that we're going to do is going to be purely cloud dedicated. We're not trying to do some sort of BYOL, hybrid, so on and so forth like that's going to evolve and potentially become part of our offering over time, but as far as what we're trying to solve for, you know, operationally today, it's going to be pretty discreet, transacted through marketplace, fixed capacity. capacity, fixed term, fixed price, and we're not going to have the nuance with potentially some overage elements to it, but we're not going to have these nuances of kind of multi multi-cloud, you know, on-prem, you know, option rights, so on and so forth. Like, that's something that we can evolve into. Absolutely. I mean, this is what we are going to be continuously working on with Jason's suggestions on how, like, I'm really eager to figure out the vast units of measurement for D and C. So I think that's something that we just have to be Yeah, continuously reiterating on and figuring out how to do that. This must be a Rennan conversation, Rennan shut down. I brought this idea, I showed examples from Snowflake and Databricks and just like you did Jason, Rennan shut it down. But I think, I mean, if we're serious about this and maybe, you know, it will take a while, long-term it will solve all the issues because we can just define units, different type or different number of units for on-prem resources and cloud resources, keep the model consistent cloud and on-prem it's just cloud servers gives you different units than on-prem servers right and and the way we we have our formula calculate that will embed the differentiation or the the pricing positioning that we want to have so I mean it's a bigger conversation but I think I think that's the way to go if we want to solve all those problems But with that, I know, again, it's a different conversation. Both Snowflake and Databricks, this is actually what I'm replying to your email, Jason, both of them have their sophisticated pricing for the data, the advanced data use cases, but for storage, they have a very simple model. is a DSU, Databricks Storage Unit, which is really simple and based on performance and capacity, which is to go back to Yancey's point about how customers would compare VaST to, let's say, NetApp's cloud offering. We need to also think about that. But anyway. Hey, Tober, one thing. this and this is I know I raised this yesterday and Eric said you know kind of different issue let's take offline but I'll just put this seed in just plant this seed in in your head. We do have a pricing disparity issue outside of the cloud business where we have you know similar customers paying vastly different prices and actually a wholesale change in pricing model is something like units could be. do a lot to help with that issue as well because it's a it's a mechanism to to kind of normalize there so just something to put in the thinking there there's various ways of solving that right I mean charging for features is another option again the guiding principles from our leadership was you know it's we include everything right I mean So, even if we had just simple feature packages priced differently, then customer A would say, "Hey, I'm paying X amount of dollars," and customer B would say, "I'm paying half of that," but maybe they're not using the same feature package, maybe they're using less features, so that's why they're paying half. Right now, it's all or nothing, and it's very easy to compare. So I believe that we need to apply more sophistication to the pricelist regardless, but unfortunately we've been stuck with coarser capacity. I understand the top-down guidance, but the simple reality of that is that level of simplicity only works if you have... of more pricing discipline, and so it's like, we can do that, but we need more pricing discipline, but we can take that offline. - Yeah, I agree, and we have to make it so comparing between two deals won't be apples to apples, right? There'll be more parameters in the quote, right? better than just two lines, right? And I like the simplicity, but like you said, right, it causes other issue. - All right, Cognizant, we got eight minutes left. There's still kind of a lot more on just the pure blocking and tackling side of things as it relates to GCP, and if we need to set up some more time, maybe with a smaller group, we can go through that. One of the pieces that we're going to need to get a better understanding on in terms of how this will all flow is just kind of billing, invoicing collections through the marketplace and how we'll be set up from a GCP perspective, kind of measurement mechanisms, how frequently we get paid out, reporting dashboards, our ability to reconcile with our own internal system. So on and so forth, and so, you know, I kind of have a whole list of things here that, you know, we're going to need to get visibility into and build some control around. I don't know if somebody wants to give a quick overview of kind of how this should work or is intended to work or is currently set up today, or if we should just set up a whole system. So I'm going to go ahead and Yeah, I'm not sure who to ask, so I'm asking everybody. So the billing and the invoicing, of course, comes directly from the marketplace that you transacted through. So I mean, there's no invoicing involved for us, it's invoiced through their Google accounts. Yes. an existing approved vendor of course, as you know, with Google, with AWS, with Azure, with OCI, whatever hyperscaler they're already in, and it basically just goes into their billing process, their invoicing, their, their, yeah, you can actually set, like, want to do plus 30, plus 60, whatever, you can actually set that in. But Google or the hyperscalers are basically doing the invoicing and everything for you, and then they, they pay you. So we need to issue only one, I assume one invoice to, uh, Google every month. There's no, no invoicing, they just, I think they just going to remit payment to us, we need to create a dummy invoice, we can, but ultimately, we need to, we'll need to figure out how to set these up customer by customer and our system from a RevRack standpoint, right? Because each one of them has to have its own opportunity, price, term, etc, and then if they're fixed price fixed capacity contracts, you know, it's pretty easy We have a start and an end date and we recognize revenue accordingly The variation is going to come through overages and so we're going to have to have a mechanism to monitor and apply overages um, and then we're also going to uh, you know need to have a mechanism to You know effectively reconcile the expected receivable from GCP with what ultimately gets remitted to us, and so there's a there's probably a portal we need to get access to to understand there's some reporting, you know, I don't know if there's an account team at GCP that we can get some mock reporting so we can understand exactly what's going to get sent to us and we can start building our own processes around. that. I'm sure we're going to have some usage and other reporting mechanisms within Polaris or TACL where we can reconcile against what GCP is reporting to us so we have an ability to validate you know that what they're reporting to us is actually complete and accurate and what we expected to see. So there's a number of these things and that's kind of what's all implied like I know big picture what's gonna happen but we got to figure out like how we actually go tactically build these motions inside of vast because this is new for vast and it's not something that we've done before and and so we need to get ahead of it at some level versus chasing our tails and waiting until it comes, right? And so, Yancey or Eki, I don't know if there's there's somebody we should be connecting with to, like, get through the boring details of all of this stuff and making sure that, you know, we can kind of mock this through our systems and we have an ability to kind of preempt what's going to come to us, and that way it's not going to be a gating eye. or slow us down when the when the first report comes and all of a sudden we're scrambling trying to figure it out. I think we should do this through time. When we're expecting to have our first customer? Ideally November, right guys? Yeah. Yeah. Is there a pipeline like? Yeah. a pipeline report Lior you have a pipeline report for GCP right we have a pipeline I would say November December is the first transaction really depends but yeah let's let's cover it all but very fast after we cover it with GCP guys the first transaction on AWS or Azure will not be months after to be after yeah so I did that you want to have a single image on one you know that really works but then once we figure it out let's do the same for the other two and when we're done with the first three we need to do the same with OCR so it will all be one after the other Jason or Lee how to say your name? Sorry. Yeah, it's perfect. Okay. Wouldn't it be interesting for you guys or Timo to actually also be like involved with the tackle if we want to be able to tackle all of it in tackle, you know? Absolutely. There's going to be a, I think tackle is going to be important. not only for this, but certainly as we move forward into usage-based and consumption-based. There's a lot of control elements we're gonna have to work through and understand, you know, how the metering engine, so on and so forth, how we're reconciling data between systems. So, yeah, I think we should have. finance you know sponsor or two that's sitting in implementation and has the ability to kind of listen in and provide input as necessary yeah but I mean the most important part is the source of truth for all measurements matrix usage consumption capacity whether it's private pay go or committed it's Polaris. Polaris is sending all that information to TACO or sending all the information to each one of the marketplaces when we go pay go. So AKB also have to take into account like the financial reporting from Polaris. Because you have to be able to, like, even though we sent all the metrics on how to charge the end customer to Google, AWS and Azure and they charge on our behalf, we still have to have a procedure that actually checks that we got paid. exactly by the matrix, you know, it's a guess. I do need to drop this. Thank you. Yeah, we'll find some more time, guys. This has been a helpful start. Appreciate it. Yeah, likewise. I'm going to go ahead and share my screen here. So, I'm going to click on the link and I'm going to go to the chat, and then I'm going to type in the name of the person that I'm going to be talking to, and then I'm going to click on the link, and then I'm going to click on the link, and then I'm going to go to the chat, and then I'm going to click on the link, and then I'm going to click on the link, and then I'm going to click on the link. >> Res, hello. Hello, can you hear me?

[01:01:01.35]  Jason ValleryGood, now by yourself.
```
