---
type: "Customer"
title: "Walmart hybrid lakehouse architecture prep"
date: "2025-11-06"
account: "Walmart"
folder: "Customers/Walmart"
participants: "Mikey, Brett, Jason Vallery, Matt, Avi, Lior, Jer, Paul, John Heidgerken, Siyash"
tags:
  - "type/customer"
  - "account/Walmart"
source: "00 Inbox/Transcripts/20251106 0803 Parallels Transcription.txt"
---

# Walmart hybrid lakehouse architecture prep
**Date:** 2025-11-06 Â· **Customer:** Walmart Â· **Folder:** Customers/Walmart

> [!summary] Executive Summary
Internal prep to shape an architecture whiteboarding session with Walmartâ€™s Lakehouse team. Walmartâ€™s current posture: Azure for dotâ€‘com systems, GCP (BigQuery/GCS) for enterprise analytics. They want to repatriate analytics to two onâ€‘prem sites while keeping a consistent lakehouse view across GCP and both sites. Immediate ask: two VAST clusters (Region 1/2) in Q4 for pilot testing. Scale is extreme: initial ~450 PB, growing to ~770 PB by 2029; daily replication target ~10% of the lake from GCP to onâ€‘prem (estimated sustained ~5 Tbps). Walmart previously floated 10 Tbps performance targets and large change rates. Two onâ€‘prem DCs run activeâ€‘active with >30 ms latency. Walmart prefers GCSâ€‘compatible APIs; S3 alone is not sufficient. Nearâ€‘term path likely uses SyncEngine for nearâ€‘realâ€‘time replication plus DataSpaces across onâ€‘prem sites; product gaps include GCS API compatibility and stronger consistency/writeâ€‘lease semantics. Team will compile targeted questions (POC scope, schemas, queries, governance, bandwidth) and try to schedule an inâ€‘person session next week, pending Walmart stakeholder alignment.

## Stakeholders & Roles
Mikey, Brett, Jason Vallery, Matt, Avi, Lior, Jer, Paul, John Heidgerken, Siyash

## Key Facts (Context, constraints, signals)
- Walmart uses Azure for dotâ€‘com and GCP (BigQuery/GCS) for analytics
- Goal: hybrid lakehouse with consistent view across GCP and two onâ€‘prem Walmart sites
- Immediate ask: deploy two VAST clusters (Region 1 and Region 2) for Q4 testing
- Scale: ~400 PiB (~450 PB) initially; growth to ~700 PiB (~770 PB) by 2029
- Daily replication target: ~10% of lake from GCP to onâ€‘prem; estimated ~5 Tbps sustained
- Prior figures mentioned: up to ~10 Tbps performance targets; high monthly change rates
- Two onâ€‘prem DCs with >30 ms latency; deep fiber interconnects (capacity TBD)
- Workloads include Trino/Presto, Spark; tables in Delta/Hudi; BigQuery access in GCP
- Walmart favors GCSâ€‘compatible API; S3 alone not acceptable longâ€‘term
- Pilot now through roughly Sep/Oct next year; 2027 is target for full project if approved; budgets finalize end of next calendar year

## Outcomes (Stage movement, agreements)
- Agreed to prepare a targeted question list for Walmartâ€™s Lakehouse team
- Plan an inâ€‘person architecture whiteboarding session with Walmart (aiming next week, pending scheduling)
- Align internal approach: nearâ€‘term SyncEngine replication from GCS plus DataSpaces across onâ€‘prem sites
- Acknowledge product gaps to evaluate: GCS API endpoint, stronger consistency/write leases, GCS changeâ€‘feed integration
- Commit to propose Q4 configurations for two VAST clusters for pilot validation

## Decisions (What we/they decided)
- Use SyncEngine for the pilot to replicate from GCS to onâ€‘prem VAST clusters
- Pursue GCS API compatibility on the roadmap; S3 alone is insufficient for Walmart
- Focus pilot on real Walmart workloads (tables/queries), not synthetic benchmarks
- Consolidate questions and send to Walmart before scheduling the design session

## Risks (Budget, timeline, legal/security, competitive)
- Network throughput may be insufficient for sustained multiâ€‘Tbps replication from GCP to onâ€‘prem
- Strong consistency across GCP and two onâ€‘prem sites is nonâ€‘trivial with current capabilities
- Product gaps (GCS API, writeâ€‘lease semantics, changeâ€‘feed integration) could delay timelines
- POC scope and performance targets are immature/fantastical without workload details
- Missing governance/multiâ€‘tenancy and compliance requirements may cause rework
- Failure to engage the right Walmart stakeholders (Lakehouse owners, DB/vector team) could stall progress

## Open Questions (clarifications, info requests)
- Exact POC/pilot scope: which datasets, tables, and representative dashboards/queries?
- Preferred object table formats and versions (Delta vs Hudi) and schema specifics
- Detailed change rates and write/read mix per workload; clarify 10%/day vs prior 10 Tbps claims
- Does GCS provide a change feed Walmart expects us to consume; required latency and ordering?
- Required API surface: strict GCS compatibility vs acceptable deltas; timelines for acceptance
- BigQuery interoperability expectations if VAST DB or object access is used in GCP
- Governance: multiâ€‘tenancy, RBAC/ABAC, auditing, data residency/compliance requirements
- Network plan: provisioned bandwidth and paths between GCP and each DC; egress model
- Perâ€‘site capacity/performance targets and whether both onâ€‘prem sites must hold full replicas
- Pilot success criteria and measurement (SLOs: RPO/RTO, query latencies, throughput)
- Will Walmart test Trino/Spark on VAST and share sample data for validation?
- Who are the Walmart owners/approvers for technical and commercial decisions?

---

## Action Items (Ownered & timeâ€‘bound)
> Use `ðŸ“… YYYY-MM-DD` for due dates; optionally add `â³`/`ðŸ›«` and `ðŸ”` where relevant.  
- [x] Compile and send consolidated architecture questions to Walmart (Vandana) by EOD @Jason Vallery â« ðŸ“… 2025-11-06 âœ… 2025-11-08
- [x] Secure the right Walmart stakeholders (Lakehouse, vector DB) and coordinate the design session @Mikey #walmart â« âœ… 2025-11-08
- [x] Follow up via email with answers to prior cloud questions raised in Slack @Lior ðŸ”¼ âœ… 2025-11-08
- [x] Align with Alon and Andy on SyncEngine pattern and lessons from the Wave project @Avi ðŸ”¼ âœ… 2025-11-08
- [x] Produce Q4 configurations for two VAST clusters (Region 1 and Region 2) for Walmart pilot @Paul â« âœ… 2025-11-08
- [x] Draft pilot test plan framework and required data/artifacts list (with sample query set) @Matt ðŸ”¼ âœ… 2025-11-08
- [x] Validate GCS changeâ€‘feed support path for SyncEngine and outline required engineering work @Avi â« âœ… 2025-11-08
- [x] Extract insights from Walmart tech blog links to inform architecture and test plan @Jason Vallery ðŸ”½ âœ… 2025-11-08

### Followâ€‘Ups (Customer / Us / Partner)
- [x] Provide POC scope: datasets, schemas, sample data, and representative Trino/Spark queries @Vandana (Walmart) â« âœ… 2025-11-08
- [x] Confirm network bandwidth plan and paths between GCP and both onâ€‘prem DCs @Walmart â« âœ… 2025-11-08
- [x] Deliver governance requirements: tenancy model, access controls, auditing, data residency @Walmart â« âœ… 2025-11-08
- [x] Clarify object format standards (Delta/Hudi) and BigQuery interoperability needs @Walmart ðŸ”¼ âœ… 2025-11-08
- [x] Confirm API requirement and acceptance for GCSâ€‘compatible endpoint and timeline @Walmart ðŸ”¼ âœ… 2025-11-08
- [x] Agree pilot success criteria (RPO/RTO, query SLAs, throughput targets) @Walmart ðŸ”¼ âœ… 2025-11-08
- [x] Confirm availability for inâ€‘person architecture whiteboard session (target next week) @Vandana (Walmart) ðŸ”¼ âœ… 2025-11-08

### Next Meeting
- Next meeting (if scheduled): **(none)**

---

## Task Views (this note only)
```tasks
not done
filter by function task.file.path === query.file.path
group by priority
sort by priority
sort by due
```

## Original Transcript
[00:00:00.45]   Remotein regards to GCP and how Vas can integrate with it, what their hybrid cloud would look like, and so, I wanted to have Lior on this call with us from a line side with GCP and then Avi. I alone mentioned you as being the guy to work with. So, from an engineering perspective, and we want to make sure that you had purview to this as well. So I'll kick it off. >> Hey Mikey, Mikey, let's do two things real quick. So Jason is new. He just came on about three weeks ago. So why don't we let him introduce himself and give us his background and then his role here at Vast, and then for the folks that don't know Avi on the line, let's have him do the same. >> Yeah, I was just about to do it, so you stole it from me. That's what I do. That's what I do, Mike. I steal thunder. Go ahead, Jason.

[00:00:51.09]  Jason ValleryYeah, thanks, Brett. Thanks, Mikey. So, Jason Valerie, I joined VaST, as Brett said, about three weeks ago. I'm joining as Vice President of Cloud Product Management. You know, focused on making VaST successful on the hyperscalers and, you know, the stories like this Walmart operation. Prior to Vast, I was at Microsoft, I spent the last 13 years on the Azure storage engineering team as product management for Microsoft's object storage platform, which is, you know, a lot. Walmart is one of Azure's key customers, so I have some exposure and knowledge about them as a customer and their use of Azure storage. it's not this workload. Microsoft certainly was very interested in winning the analytics workload, but the way Walmart thinks about their hybrid cloud strategy is that Azure primarily has the dot-com of the business, so this is all of their order management systems, retail, obviously Walmart.com itself, and all of that run on Azure, and then the back-end system. like analytics run on Google. So that's kind of their posture with that. You know, key takeaways from the meeting, you know, there's a sign that they want to repatriate a lot of their work that they're doing with both Google and Microsoft on-prem. This analytics workhouse seems to be one of the things that would likely move first. It sounds like crawl, walk, run, of trying to run in a hybrid state where they're bursting. analytics capacity back onto their on-premises environment, and ultimately, their holy grail view of this is they want strong consistency of their lake house across Google and then two on-premises Walmart sites. That's a tall order. No storage platform has the capability to do that, particularly when you think of-- GCP as the source of truth for the data. All of their data ingestion pipelines go through GCP today and leverage BigQuery, and so we have to come up with an architecture that gets them as far as we can with the current capabilities of the VAST platform and then work with them to identify what roadmap items would be necessary to get them to a complete solution. complete architecture. Their timelines are such that they're kicking off this POC or pilot now, and that we would work with them up until roughly sort of September or October of next year, and at that point be in the sort of decision frame of if they're actually going to pull the trigger to do the entire project for calendar year 27. Budget cycles likely be finalized at the end of next calendar year. I put more details into the Slack canvas page. I don't know how we collaborate right here, but that seems like a good way to do it, including a number of what I think are open questions around how this architecture could potentially work, things that we didn't get teased out of that meeting. As a key follow-up, we agreed with them that we would next do sort of a an architecture design whiteboarding section in person with their Lakehouse team and so that's this is the prep call for that where we can kind of talk through what we have in the stack today, go back to them with some additional targeted questions, anything the team identifies, and hopefully be able to get together a rough architecture view and how we would approach this problem so that when we meet with them we've already got a good understanding of how to land the solution. So I'll pause there. I don't know Brad, Mikey, you folks who were in the meeting as well, any other things to add?

[00:04:30.66]   RemoteNo, I don't. We can get into that in a little bit more detail. Mikey, obviously, was not on the call. So I think we can get into Matt giving his perspective on things. But I appreciate that feedback. So Mikey, back to you. Yeah, and Matt, before you go, just so that we know who all is on the call, for you, Jason, My rep, my S.E. is Paul, Jer is the CTO, field CTO for our area, super involved with Walmart, John Heidgerken is the DM for the system engineering part of the business as well, supporting Brad and Paul's boss. So, just a lot was said in there and then Avi, if you want to give a quick introduction real quick, I think that'll be helpful. Yeah, so as mentioned before, I'm one of the old-timers in Vast, so I did a bunch of stuff, but now I'm focused on architecture, mainly on the data space side, so all replication, global namespace stuff are part of what I'm doing with right now, and that's kind of... The position for this topic Perfect and Lior, I wouldn't leave you out my man. So good. I'm the cloud guy Love it. All right, cool. Matt. I'll pass it over to you brother. Yeah for sure - And I'm gonna focus a little bit more, not so much on the hybrid VAST to cloud piece, but, and I think my piece is pretty short, but in the meeting with Anil, I know that in the past when we've met with Walmart, specifically around this big data project they've had, well, I'd say there was one contact who was not so open to, using VastDB and some of the other pieces outside of just the object storage. I think that the conversation with Anil and Jeff went really well where, you know, Anil said, you know, hey, he was primarily saying, hey, high-performance object storage, high-performance object storage, that's kind of what he had in mind, and, you know, I think Jeff, mission accomplished to get him thinking about, you know, more. than just that. Specifically, it sounds like they're in the process of building out their vector database architecture, which we'll have a follow-up to get with that team and start to talk to them a little bit more. But overall, I think the message from Anil was, "Hey, I want to try everything that you have and see where these things fit." So again, I think my piece is pretty short. You know, Jason definitely articulated well on the, you know, the ask of the on-prem vast system and how we operate in GCP. So awesome. So I think this is a good, a good kind of place to start. I'll kind of give you guys the overview of what we know about the project and what they asked for. This will be the first time that you have actually seen this RFI and what really sparked all this conversation We've been having with them over the last couple of weeks Give me one second. Let me pull up my screen real quick So that way we can all be on the same page and then what I want to do after that Jason I'll pass it over to you just to pull up the The slides or what you shared on slack channel we can walk through through some of the requirements and some of your thoughts on that as well. Does that work for everybody?

[00:07:58.54]  Jason Vallery- Sure.

[00:07:59.37]   Remote- Cool. One second. - Jason, I can see that you're back home.

[00:08:15.63]  Jason Vallery- Oh, I landed at 4 a.m. this morning, so I'm still half asleep, guys.

[00:08:19.24]   Remote- Yeah, it's either you're back home or you have the same desktop background even when you're not home, which is awkward. You should do that. It's everywhere you are, same background.

[00:08:28.72]  Jason Vallery- No, no, I did make, it was my, with all the FAA stuff going on here, the flight was delayed, so like I said, I got into my house at 4 a.m., so.

[00:08:38.30]   RemoteIt was a long night. I'm glad you made it safely. Yeah. All right. Can everybody see my screen? Yes. Cool. So, just a level set. Walmart specifically wrote this for Vast. This was given to us about, I want to say, two months ago. been a ton of discussion. So, from a capacity perspective, Avi, I know, at the end of the day, Shahar and Alon is going to say, well, what is the commitment, right? Coming from, what is the end goal? If we're going to have to put something into our features and functionalities, then, you know, what is the scope of the project? So, at a high level, today, they were talking about 400 petabytes, pebbybytes. in vast terms is 450 petabytes that they would be looking into so going back to what Jason just mentioned from the October time frame of next year if we have everything that they're asking for that's what they would be looking at transacting based on what we've been told and then they want to grow that environment quickly to 700 pebby bytes which is roughly 770 petabytes, vast terms, by 2029. I'll stop there. If anybody wants to add any commentary there, Jer or John, Paul?

[00:09:55.78]  Jason ValleryOne of the things I'm certain in relationship to the capacity, and this is in the notes, they have to replicate roughly 10% of their lake house from Google back on-prem each day. in a streaming fashion, because that's the churn of their delta tables, clarity, I don't know how those tables are structured, but, um, which is crazy because if you go do all the math, you're actually talking about a sustained five terabits of replication traffic going from GCP back into Walmart data centers, unclear if they have network links. and support that kind of throughput and how we would work through that kind of write velocity, but this is another key part of what makes strong consistency very difficult.

[00:10:39.84]   RemoteOkay, yeah their answer when questions were brought up in a previous conversation about bandwidth was just a simple "that's configurable" as in they'll just... Buy what they need to buy in terms of bandwidth. Yeah There in relation because I was just about to ask that question in relation to what they shared with us Last week around the 10 terabits requirements. How do you think that relates to this? In regards to what they said yesterday to Jason Or does it not relate at all? Well, so what they previously told us in conversation was a change rate of 100 petabytes a month of new data coming into the lake house and replacing old data cycling in and out. So I haven't done the arithmetic this morning to see how that correlates to, you know, what they told Jason about rate of change. The bottom line to all that is that it is a very high rate of change that in the data set that's going to need to be common across multiple clusters, physical and cloud, right? On-premises and cloud. Yeah.

[00:11:57.16]  Jason ValleryYeah, I mean, there's roughly a line. I mean, I think you're talking about three pebble bites a day and they're talking.

[00:12:06.72]   RemoteYeah.

[00:12:07.30]  Jason ValleryYeah. Quite a bit. I guess quite a bit more than that. If you use the 10% number, they were very, like, we heard a few different numbers and they were kind of hedging and just swagging number. I don't think they had a concrete estimate in place.

[00:12:19.78]   RemoteYeah. I don't, I don't think they've, you know, I don't think they're being precise. in any of these, but they're roughly the same, you know, they're in the same ballpark. It's a gargantuan rate of change that needs to be kept in sync between. What they've told us in a previous conversation was their plan is two on-premises locations. that would be either very low RPO or even synchronously replicated and a cloud copy that also has to be in sync. Okay, as far as for Workloads what they would they have shared with us. It's uh, and I'll share this back with this entire thread So you guys will have this in the email today, but it's a variety of different Metal and analytical use cases in the scope for this project going back to what Matt mentioned as well Obviously, there's a big push and all the just was gonna be pushing for us to get the database into scope as well, but for what they're looking for from us today, this is just a handful of different projects or analytical use cases that they'll be bringing up. Now from the actual must-haves from VAST, and I think that this has changed in a way, not for the worst, but just more, just learning more about their environment, Dave. They provided more details as to what they're looking for, and I think that this could be a good segue to get into the discussion that, Jason, that you wanted to have in regards to the future features that we would have to implement into our product in order for us to really meet all of the requirements. All of these things that we have here today, VASC can do, but there is a piece that's missing and it's super important for us to be able to move this opportunity forward. So, Jason, if you don't mind pulling that up, I think that that'll be helpful to level us up with the rest of the team. Hey, Mikey, just a quick question before we go into that. Do you know if they have a plan to POC or test some of the workload? I'm thinking, like, specifically, are they planning to test some of the workload? take like a Trino workload and run it on Vast? Like, do you have some insight into what that looks like? - I don't know. I won't say that I know for sure. However, I can find out. - Okay. - The assumption would be yes, 'cause they want to test it for you. I guess there's another piece before we jump into the piece where you, Jason, is. What they're looking for, and the immediate ask, is that they get two vast clusters in their Region 1 and Region 2, so that way they can start doing this testing. So that is what's immediate and is on the table now for Q4 for us, and that's what we're kind of building towards. all this features and functionalities that we need to talk about now, the timeline is, based on what Jeff was saying, it'll take a year for us to get to that point. So that's why we're doing this session today. So for the, just the quick summary of the testing is they've asked us for some configurations so that they can validate performance and replicate. and those those kinds of things the way they're conceiving that up till now prior to the dinner with Jeff was I think that they would just use s3 objects and in you know, whatever format they plan to use and that they would test queries against that I Hopefully what has changed since the dinner is that they would also entertain doing some level of testing of the vast

[00:16:12.66]  Jason ValleryDatabase itself as an alternative to that. Okay. One of the things that was clear is the protocol and being S3 is not a long-term solution. They today have a ton of code written against the Google Cloud. storage APIs and so they were pushing hard for us to make some level of commitment around doing this with the GCS API. So ultimately that would be a product that we have today we'd have to go and implement the Google Cloud Storage APIs. I think when you layer that with the question of database it would be, I mean, we will continue to push on this but if they're going to remain in Google Cloud, it'll be hard to get them to adopt database and directly consuming it if they're looking purely as object storage to be how they store all of their tables. So I think that would be the big win, but that wouldn't be possible until they fully move off of Google if they continue to have some sort of hybrid solution. So I think-- term and in what they were looking at or what we kind of high level discussed was if we could deliver theoretically a GCS compatible API or endpoint by the time they're ready to start moving something like this into production that might be acceptable to them. So was was there a

[00:17:33.36]   RemoteDiscussion of the vast database on vast on cloud in in GCP? That was more, I would say, to be determined. I think the discussion of Database was more, hey, we're open to trying this. We're open to using this, and then it kind of shifted gears to the GCS piece Jason just highlighted, and it was more of just like general like, "Hey, can you support this type of thing?" No, I wouldn't have expected any kind of commitment for something that's a completely unknown technology, just openness to conversation about it. So I don't want to derail this on a tangent.

[00:18:23.32]  Jason ValleryThat direction. So, you know, it's a good point. I mean, I think obviously that's the direction we want to push them. The GCP dimension also layers in how do you make that database with compatible with BigQuery, right? Because BigQuery is ultimately the thing accessing the data in GCP. So, there's a lot of interop problems to try and solve to get that to be a valid POC.

[00:18:45.79]   Remote- Yep.

[00:18:46.63]  Jason Vallery- And we continue to bring up with it.

[00:18:49.20]   Remote- Cool. You got us excited, let's see the details now.

[00:18:54.71]  Jason Vallery- Yeah, I mean, I can just at least just share my, what was in Slack, right? So this is the Slack canvas that I put some notes in there. I think there's a lot of open questions. So, you know, how we would approach this from an architecture perspective, the first problem we're going to run into is just how to get the data from GCP back into Vast on-premises. Obviously, today it's Sync Engine and that, by definition of that approach, means we're responding to some sort of change feed or listing of, you know, instances in Vast. of what's being put into the Google Cloud Storage bucket and then async copying that down into Vast. So, I mean, that's the first big hurdle to overcome with a long-term solution is how can we make that with what they're looking to from an RTO, RPO perspective, look a little bit more like strong consistency. You know, I'd be... curious from the team if there's any thoughts on like architecturally how we want to approach this, but assuming we're going with Google Cloud as the system of record and GCS is that, you know, Avi, have we considered anything with Sync Engine that could be appropriate here?

[00:20:17.43]   RemoteUh, I'm, I'm just too tired. trying to figure out, we're talking in terms of a disaster recovery of our RPO and RTO, but are we consuming this content as it arrives to an on-prem site or we're looking at only the durability? Is there a collaboration?

[00:20:36.25]  Jason Vallery- I think the version of this looks like. So they have an overlay system that they describe that when one of their end users comes in and submits a job, they currently can then dispatch the queries off to be ran in Google today, and so the vision here is that the data that's currently sitting in the lake house in GCS will be replicated back on-prem, and they would be able to use analytics tools running on compute, on-prem, to query the same lake house, and so, idea being, they could do the transactional reads to satisfy all of those dashboards and queries that their business users are putting into the system from a copy of the data set sitting in VAD. on-prem while ingestion pipelines continue to run inside Google and that there's a consistent view across the two data states. So the data is on GCS on

[00:21:37.75]   RemoteGoogle and they want us to find a way to move it with them on-prem and to give it the same GCS access on-prem. On-prem. Exactly. The NetNet. Okay. So they're not looking for us to run anything, any of our clusters on cloud. It's more about how do we move the data and how do we make it look exactly like GCS when it gets on-prem.

[00:21:59.09]  Jason ValleryRoughly. I mean, I think there's probably an opportunity. I mean, we definitely brought up, you know, there may be a necessity for us to run VAST in VMs in Google. but maybe that sync engine or, you know--

[00:22:13.35]   Remote- It's okay, I'm not trying to invent a use case or a requirement doesn't exist. I just want to see that I understand the requirement, and so I am aware of like Wave, as an example, it's another project where the data sits on Azure Blob and it's tens of petabytes to move into vast. not on-prem, but on CoreWeave, and Alon and Andy were leading that there with SyncEngine and trying to figure out how to do it the right way. Yeah. So Avi, you probably know more about it, but it sounds like SyncEngine needs to be a mechanism that moves the data, and it moves the data all the time with changes. It's not like one-time move. It's something that needs to be consistent, correct? I'm also leaning towards a vast instance that does our native kind of traffic and also synchronous, well, having a consistent view of the content. So I'm not sure about,

[00:23:16.09]  Jason ValleryI mean, SyncEngine is Async by definition, so it is a question of how can we make this a strongly consistent view of the data? And you know, I think when you look at roadmaps, you could make a case that they could, if We have a GCS point you could run. GCS front ends invest in Google Cloud and effectively that becomes what I'll describe as a reverse proxy to the data setting in GCS and then that can have a strong consistent view with data spaces and then you can kind of get to this vision that seems to be the long-term way to approach the but that isn't something obviously we have in the product today.

[00:24:00.88]   RemoteRight that's what we're trying to get yeah it actually is not well given the internals we do have async replication alongside global namespace so given we're talking about the s3 protocol side of things rather than then full-blown vast DB we can expose an active, active view of the content while shipping data asynchronously. So in terms of, you know, consistency and latency, that's what we were striving for. - Yeah, but the source of the data doesn't sit on VAS, source of the data sits on GCS. on the Google Cloud Storage. - Yeah, I'm talking about if we have a vast instance-- - So right now, it seems like, you know, immediately what they wish to do is they wish to figure out a way to move the data on-prem and move the data with the same protocol on-prem, but it's going to come out of the origin storage, not going to come out of vast. It's 60-piece storage, the target is vast.

[00:25:11.42]  Jason ValleryAnd I mean, when we propose these architectures and we have this conversation with them, I think these are the trade-offs we'll highlight of what can we do today, how would this work with Sync Engine plus data spaces, what are the product gaps, and what are we committed to close by time they would take this into production in calendar year '27? I think those are all bullet points we have to land on. conversation and so I think you know clearly what we got today it is we use sync engine to make a real-time stream replication of the data coming out of Google Cloud Storage on based on some sort of change feed ideally with filters and compaction and that would be what they would use for the POC but the to be something that is a complete story against the requirements.

[00:25:56.29]   RemoteYeah, I understand. I really think, Mike, I think that's, again, interesting data here and there is much to do. I think we should really talk to Alon and Andy. on what they have kind of architected for Wave, because it's a different problem, but it's the same scale of a problem. The origin there is Azure Blob, the origin here is GCS. The target there is a vast cluster, and it's something that they add to Taylor that will not just be one-time data movement, because they're creating data there all the time. Now, moving forward, like a year from today, vast architecture on clouds will enable us, I'm now giving you an imaginary vision, enable us to really have one catalog that will oversee also the cloud storage, GCS, and then you will be able to use the vast application technologies to move data from GCS to a vast cloud. as their own prem and maybe that can be expedite, right? But right now it doesn't exist, and right now we, you know, use what Alon and Andy did for Wave to figure out what's the fast path forward.

[00:27:15.13]  Jason Vallery- Yeah, maybe what we could do in terms of best use of our time is if we focus in on the questions we want to go back to Walmart with, right? Because we honestly didn't get. a lot of time with the team that's responsible for this workload, and so at least insofar as the knowledge I captured, there were a lot of holes, you know, maybe we can just kind of focus on are there additional things beyond what I wrote down here that we want to go back and ask them that would help us better understand the options space in terms of how to... approach this, and what I'm specifically pushing on is like, are there things we can do higher level in their analytics pipelines to optimize? That would make this a more, you know, digestible problem.

[00:27:57.83]   RemoteThat can work. One question before we start, Mike, in Slack, you asked a lot of other questions, which are more about So that's not a priority right now, right? Answering those questions, or at least not for this team. I would say that it's not that it's not a priority. I think it's good for us to know. I think there is a world where they could consider Vast on the Cloud. So it's good to at least have the details around it. But for this... specific conversation. I think towards the design architecture, I think it's more important. Okay. So unrelated, I will follow up with an email with all of your questions and all of the answers, and if you want to ask others, just let me know. Let's go back to this. Okay. Appreciate that.

[00:28:48.86]  Jason VallerySo, you know, one of the things I would ask is from a VT. perspective who's our analytics expert that just really knows presto trino how delta tables work how the different formats because i think we know they use hudi like who do we have that would be

[00:29:06.79]   RemoteYeah that would be myself and see you off on a call yeah yeah so i mean that that's where we

[00:29:14.51]  Jason Vallerywe have to get in here is. really look at it from that workload perspective on how we can optimize with some of the higher layer abstractions. So I think I would turn to you guys to help poke holes in the set of questions we have here.

[00:29:27.09]   Remote- Poke holes, how, just in terms of?

[00:29:35.01]  Jason Vallery- Like, you know, if you were doing this as sort of like a big data architecture. You have a set of requirements and you're trying to be agnostic of the underlying infrastructure. What do you need to know and what can we do to solve this at that layer, and what would you want to know about their current use to help inform those options?

[00:30:00.99]   RemoteTypically approach this and then you know I'll let Siyash chime in as well but we'd want to take a look at like the the actual data and the and the actual queries that they're running right so like you know down to the table level taking you know let's say for example they have a delta table and it's running a bunch of trino queries and those are you know that that the those trino queries are firing you know are supporting some sort of of Tableau dashboard or whatever, we'd wanna take a look at that specifically to see how we can optimize that, and that's pretty standard for most kind of how you would evaluate analytics workflows. But Siyash, any comments on that? - No, you're spot on. Basically we get the scheme of the table, sample data. or real data, if they can share it, and then the pipeline that they are running today. So it could be a data transformation job on Spark. We want to understand which tables it interacts with, how it's transforming that data, and then there's usually, let's say, a set of gold tables that are connected to dashboarding tools and whatnot, right? So that's usually the analytics pipeline. They may have something different, but we need to understand the pipeline, plus each stage of the pipeline in terms of what the schema is for each table and how it gets transformed as well. So based on that, we can make decisions in terms of how we can tune it or how we can make it better or worse.

[00:31:29.01]  Jason ValleryWhat's clear is the scale of what they're doing here is very... ambitious, and what they've got, based on what I'm interpreting, and I don't know if you saw, there were a couple of links I put in there from their Walmart tech blog. This is something we dealt with in the Azure days, this same blog. Walmart's actually really good about going and blogging what they're doing, because they think they're at the frontier of a lot of these things, and so there's actually some really good intelligence we can get out of those links below. is Walmart's entire lake. So this is retail data, this is logistics data, this is, you know, every piece of, we'll call it digital exhaust, coming out of the entire Walmart enterprise, and all of the things that Walmart does, coming into a single consolidated set of tables across business units, and then downstream from that, after whatever they're doing, in terms of transformations, normalizations, all of that, a ability for various business units to go query that data, and so they've exposed to data scientists, researchers, business units that have, you know, various dashboards, a set of tools and frameworks that they can go build against. So you should think of that as like a centralized... team managing all of the analytics data across all of Walmart, then exposing out as a managed service to thousands of different users the capability to come and query those data sets to whatever end goals they have as a given business unit. So that the first article, I'm sorry, the second article. I called out, there's 2000 different users doing a million different queries across this data lake on a given month, and those are probably old data points, and so it's not one scenario, one set of tables, one workload. It's a lot of different cases that they're trying to solve for on a centralized data lake and lake house?

[00:33:27.08]   RemoteThat is the case with most customers at that scale. But every such customer has a pain point, right? And let's say when they upgrade their deployments or are changing something in the deployment, they go through an internal test process so that other workloads don't get-- affected and whatnot. So everyone has a cycle of internal testing. What we do or what we recommend is initially at least take that piece and run or emulate on WASD with the criteria of their internal QA because that covers most test cases. that are relevant for the business. That's what we did at Visa. It's not referenceable, but just calling it out, yeah.

[00:34:17.14]  Jason Vallery- So I guess one of the key questions that is missing here is what is the POC that we're talking about doing, or pilot, I think we prefer pilot, and how are they scoping that with an end-to-end workload scenario or set of tables?

[00:34:31.22]   RemoteExactly right, and that's why I asked the question a little bit earlier of just if we had a sense of, you know, what that looks like, right, because that'll give us a lot of information because, you know, and I totally, totally understand, you know, Jason, the scope and size and all of those types of things. But, you know, to my understanding, they're not moving the entire lake, right? This is a piece of it. So we just need to kind of better understand like what that piece is and what the or what they're looking to test.

[00:35:02.27]  Jason Vallery- Well, I definitely got the sense that the long-term goal is to move the entire lake. I think it'll go phases of we'll do a pilot over the next nine months or so, probably a subset where they're doing the reads and query execution on-prem, and then that would scale to being able lake house reads queries on prem and then that long-term may scale to them

[00:35:21.84]   RemoteRepatriating the entire workload. So yeah all on the table. Yeah for any of these for any of these projects though it's you know it's the the age-old saying of you know how do you eat an elephant it's one bite at a time right so that's you know kind of how we want to approach this and it you know to see off this point it's what we've done with Visa and some other customers. as well. It's just kind of getting granular. It's never just a flip the switch, move everything type of thing. We can kind of take this piece by piece, and usually we work with the customer to find their top five challenging jobs that they may want to optimize or are already struggling with either in the cloud or their existing environment, right? Testing that or bringing that workload on the POC builds confidence in everything else that they have. Because everything else, they've already running pretty smoothly, and if we are able to optimize the most challenging workloads that they have, usually customers gain a lot of confidence in us, and it makes it easier for them to-- make a decision as well. Yeah. So I would say the level of conversation that we've had with them up till now about the pilot or eval or POC has been fairly immature. They basically came to us and asked for a quote for you know storage system in effect that would have a fraction of the capacity and a mismatched fraction of the performance. Like the the original quote that they came and asked us for was for one petabyte of capacity with 10 terabits per second of performance, 80% read, 20% write. The I/O density didn't match. It's fantasy numbers. So the conversations that we've had up till now about what they would test are really about system specs and not tables or queries or workload anything. So we definitely need to mature that conversation.

[00:37:31.13]  Jason ValleryIn the conversations you folks have had or in that document, I'm curious if anything came up about access management, multi-tenancy, because clearly there are multiple different business units consuming this data, I have to assume they have some sort of like governance isolation controls. Any security related or data residency considerations associated with that? We didn't talk about that at all in the meeting, but, you know, those are key things for us to start thinking through from an architecture perspective. Do we get any feedback on that?

[00:38:08.28]   RemoteNot in this context. We, none of that conversations happened in this context, although in other contexts for other. projects that are actively being worked with Walmart, the conversations have been had about multi-tenancy capabilities. I would not imagine that they really remember those in great detail because it takes many iterations with them to get concepts through because they think about our stuff. a small fraction of the day, right? But that's definitely another thing that we need to bring into this conversation as we mature the conversation about this specific workload. So like the storage team and the folks who typically manage this type of infrastructure at Walmart are familiar. that we have with the notion that we have multi-tenancy capabilities and that we have robust auditing capabilities, but I don't think they've not shared with us any thinking internally about how that would apply to this project.

[00:39:17.92]  Jason ValleryYeah, let's see.

[00:39:31.49]   RemoteAnd I'm just because we were talking about it before Matt and see us for you guys They're gonna lean on vast to help them build this test plan like heavily That's gonna be the expectation. I'll tell you guys that right now They're gonna ask for us to basically write it in a way they're gonna have things that they want to focus on but there's they're going to lean on VaST. What are other customers doing? What have we seen in the industry? Those are going to be the type of questions that we can expect from them. If we don't get in front of the right audience and that is actually going to test the Trino workloads and Spark workloads, it's going to be very difficult to have a meaningful full test plan. With every analytics workload, we have to dive deeper into their current workflow and work through that. What other customers are doing is not going to be relevant for Walmart because that test plan is going to be specific to their jobs and workflows. We can create a generic test plan. That may not mean much to them. That will just be, you know how vast database works or how our products work, but it's not going to be relevant to their applications in their workflow, so I think we will. We can create the test plan, will drive it, but we need the other party on the table as well. as well, and the right people from the, from Walmart as well. - Okay, that, then I'll take that for an action item for myself to work on, getting the right folks involved. - I think we've identified some of them. We may not have identified all of them, but there's going to be a big overlap between the folks who drove most of the active questions on. the last call that we had about about global namespace versus replication and trying to get clear in their mind what the differentiation between those two capabilities were. Mengmeng and I forget who else was driving, andy Robb. Say again? Andy Robb. It's Mengmeng and Andy Robb is the other guy. Yeah there was a third that was asking some of the questions as well, but I think that subset is the, you know, Ming Ming in particular was very vocal, and I think knows the data layout and the requirements, and probably also some of the query stuff, and if not, she can get us to those folks. I just thought about, you're thinking of Vandana. Vandana out of India.

[00:42:01.53]  Jason ValleryYeah. Yeah. Yeah. Yeah. Yeah. Yeah. She was there. Yeah. Yep. She's so she's the product.

[00:42:12.26]   RemoteShe owns all of this. She lives breezes. Yeah. This is her baby that she's working on. Yeah.

[00:42:16.88]  Jason ValleryI mean, I think clearly as the next step, we go back to her with our set of questions and ask for if you can answer these in advance of us scheduling. in an architecture meeting, it would be great, so yeah.

[00:42:26.52]   Remote- Yeah, if there's that list of questions, I have a running cadence with her. Whatever that list of questions that we all deemed super important for what we need to know, I'll share that with her and she'll get it back to me relatively sooner than later.

[00:42:41.02]  Jason Vallery- Yeah, yeah, we should send off an email today to her. do you want to know from an architecture perspective that would help you put together the puzzle pieces for phase one and phase two of this?

[00:42:53.49]   Remote- I'll probably need to discuss it with Alan regarding the sync engine piece. But you mentioned we have, it's not a single site, right? the on-prem portion yeah I was still trying to figure out the relationship

[00:43:14.07]  Jason ValleryBetween the two sites so Walmart have a replication there yeah exactly Walmart's posture and this is across all of their systems we dealt with this in Azure is they have two on-prem data centers I think ones somewhere in the East Coast Virginia and the other ones I think in like San Antonio of Texas, they described them as greater than 30 milliseconds of network latency between them, but roughly in that ballpark, and they have deep fiber interconnects between them. Total fiber capacity is unclear, but their vision here is that those sites run active-active as well. back to the point of you're really only writing in one place. That's where the ingestion pipelines are going and the transformations, everything are happening. But you have the ability to run queries against any of the sites, you know, from the cloud, from either of the two on-prem sites. So they'll be reading from one of the three sites at any given time and writing. one of the, or sorry, they'll be reading from any of the three and writing to one. So the idea is, you know, you'd have SyncEngine running in sourcing from GCS, and then you would have data spaces connected with strong consistency between the two sides. I think there are capacity considerations and so forth. and how that would all play out to make sure you have a full replica of the data in both of the two Walmart on-prem facilities.

[00:44:47.03]   RemoteI understand. So I would assume that content creation wouldn't be easily separatable in the the sense of hierarchies I mean like different protected paths partition I would assume object creation naming will be kind of interleaved you create from different different objects are created by different sites but it's not easy to separate those so relationship would probably need the element of write leases to be able to write a reasonable performance for both sides and have an underlying async replication to compliment that.

[00:45:40.88]  Jason Vallery- I think that's right. I think that would be the. when we get to the full solution. I don't know if we need that during the first phase, but I agree, you would have to have some sort of write-lease capability completed to make that story complete. You know, in this first phase, I'm actually not sure how this works on Google Cloud, but I know both AWS and Azure support a change. feed with like you know real near real-time dump into like an Avro file or something like that that contains all of the mutations of the objects in the bucket. Does SyncEngine support that and have we tested it with Google Cloud?

[00:46:31.51]   RemoteI don't know, I'll have to work out the details of the thing in general, it's a long...

[00:46:39.17]  Jason ValleryOkay. Okay, well, we may have drained what we can get through on this call unless others have topics we want to get into, and I think next steps are to finalize our set of questions.

[00:46:54.03]   Remotego back to meet me. Yeah, I agree with that. Once we confirm that, Jason, you had already mentioned the date that you and Alona will be back in the Bay Area on the 13th. Yeah.

[00:47:07.22]  Jason ValleryNext Thursday, Alona and I have a meeting with Google, funnily enough. optimistically it was if we could get it in person next week we could do this and have the next level

[00:47:22.85]   Remoteof conversation with them maybe next friday would be ideal yeah i can i can definitely work on that um once i get the list of questions it's all summed up from your end i can share that with ming-ming and we can see if we can get something on Friday.

[00:47:39.49]  Jason ValleryI was going to cite next steps, which I think is obvious going to connect with alone on the set of questions and confirm there's nothing else we want to ask, and then we'll try to to get these out hopefully by the end of the day.

[00:48:01.73]   RemoteYeah, if that works for me, I have a couple of things I need to circle back on, but I think this is definitely a great start and it's going to take all of us to get it done. So cool. Thanks for today.

[00:48:15.46]  Jason ValleryMuch appreciated, everybody.

[00:48:16.45]   RemoteThanks, everybody. Thank you. Thanks, guys. Thank you. (mouse clicking) (computer mouse clicking) (keyboard clicking)











