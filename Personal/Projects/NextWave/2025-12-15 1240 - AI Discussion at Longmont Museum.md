**Justin Veach**: Good evening.
*00:23*

**Justin Veach**: Welcome to the LaMont Museum. My name is Justin Veach. I'm the manager of the museum's
*00:26*

**Justin Veach**: Stewart Auditorium and I curate public programs. Thanks for coming out this evening for this
*00:31*

**Justin Veach**: important and timely conversation. Before we get going, I want to thank a few folks who make our programming possible. The Scientific and Cultural Facilities District, the Stewart Family Foundation, the friends of the LaMont Museum, and of course our museum members. Do we happen to have any museum members with us this evening? Hey, members.
*00:37*

**Justin Veach**: I thought I saw some of you. Thank you. We simply can't do all that we do without you. If you're interested in finding out what it means to be a member of the La Maude Museum, feel free to grab me after the program or ask one of our staff or perhaps approach one of those folks who have their hand raised to ask them why they're members. I'd also like to thank some of our media sponsors, the mighty KGNU Community Radio out of Daryl Boulder just down the road, KUNC in the Colorado Sound. I also want to thank you
*00:55*

**Justin Veach**: for putting up with our construction and the complications that has wrought on our parking situation. So if you hoofed it from the neighborhood or had to walk through a semi plowed kind of muddy parking lot, our apologies. But what's happening is that the biggest museum in Boulder County, that's us by the way, is about to get bigger. We're expanding, obviously, we're building a 4000 square foot gallery space.
*01:26*

**Justin Veach**: expanding our lobby and completely redoing our front entrance. So that means by the time while mid-summer rolls around, we'll have three gallery spaces. One that will be a dedicated history space, another dedicated children's space, and then a dedicated rotating space for traveling shows and curated in-house exhibitions. So exciting stuff on the way. What else is happening? This weekend, we have our annual
*01:55*

**Justin Veach**: It's actually our 10th annual holiday show this Saturday. If you're looking to get your holiday thing going, this is a great way to kickstart it on Saturday. We have two shows, 3 p.m. and 7 p.m. It's a very eclectic evening or afternoon. They sell out, so you want to buy your tickets ASAP if you're interested. Let's see. Well, artificial intelligence, AI. Have you heard of this thing? Yeah. I used to get my intelligence.
*02:25*

**Justin Veach**: It used to be called artificial back in the day, but I think it has a new meaning now. We're about to drink from the AI fire hose, and we're joined by Longmont's own Jason Vallerye of Vast Data. Ladies and gentlemen, without further ado, Jason Vallerye is going to do a little PowerPoint presentation for a bit. That's going to be the fire hose part. Then we're going to sit down and have a chat where we digest some of what we've received via that fire hose, and then open it up to
*02:56*

**Jason Vallery**: Q&A. Without further ado, Jason Vallerye, ladies and gentlemen. Thank you, Justin. It's great to see so many people here about this important topic. I'm glad there's a good enthusiastic turnout. I want to start off with a bit of an analogy. I want us to all imagine we're on a beach. Unfortunately, this isn't a very beautiful beach. It's a dirty beach. It's a filthy beach. It's covered in trash.
*03:26*

**Jason Vallery**: But we're all very focused on making the best of it. We see the opportunity that this beach presents and we're all cleaning up that debris. Our heads are a little bit down. We're looking at the sand and we're scavenging through. But if we looked up, we'd notice just offshore a hundred foot wall of water tsunami about to wash away all of us in the beach and make all of our work gone.
*03:56*

**Jason Vallery**: I think this represents where we're at in society. We're all focused on a lot of important problems and we're ignoring the one that's just offshore. And tonight I want to walk you through what's coming and what I think we need to be doing about it. So let me jump in and do a bit of an introduction. So as Justin said, I'm Jason Vallerye. I grew up here in Longmont, Longmont High Class 2000, lived here pretty much my whole life and certainly all in Boulder County my whole life.
*04:25*

**Jason Vallery**: I've spent the last 25 years in the tech industry. I have been building out the infrastructure that is powering this AI era and all of the innovation that you're enjoying now. I spent the last 13 years at Microsoft building out storage and data infrastructure for Microsoft's AI customers like OpenAI. And now I'm the vice president of product management for Vast Data, which does similar for most of the AI industry. I'm also the outgoing board chair. I'm term limited.
*04:55*

**Jason Vallery**: I have a dream foundation of Boulder County. But I do want to stress everything I share tonight are my views, not that of my employer or any other organizations I represent. As Justin said, our agenda for tonight is pretty straightforward. I'm going to spend about 30 minutes walking through facts and figures and data and being pragmatic about the approach to share with you what's coming. And then I'll talk a little bit about what I see the implications are for Longmont, the way that we can get ahead of some of the challenges this is going to create for us.
*05:25*

**Jason Vallery**: and what opportunities are there behind that. And then as Justin said, we'll go into conversation and hopefully we can get the audience engaged and get some feedback and ideas from you. But I want to start off with asking you to pull out your cell phones. We're going to try a little bit of an experiment because I do want to understand who's in the room and who's using AI. If you can scan this QR code, we're going to get some real-time feedback of what percentage of you use this, how often, which age groups are kind of represented, and if you choose to,
*05:55*

**Jason Vallery**: It's optional. You can provide your email address on the form. And what you'll get from me afterwards is a copy of the slide deck and an email to some resources that you can take home and follow up with. So let's take 60 seconds and answer the four questions that you'll be presented with when you scan that code. Oh, no. Is that an issue in here? I don't know. Justin, Wi-Fi, do we have a solution?
*06:25*

**Justin Veach**: All work is well and need to be a part of
*06:55*

**Jason Vallery**: I think he said L, what was it, Justin? What's the password? L-N-G-M-T? There we go. L-G-M-T wireless. I'll give it just a couple more seconds and let
*07:37*

**Jason Vallery**: Last few folks finish up. Yeah. Oh, did we drop it? I was showing results. There we go. Hubbell Net. Public Net, I guess. Well, you folks feel free to continue filling out the survey and we'll get final data towards the end. But we'll start kind of doing some analysis on this. And what I see is 85% of you use AI at some point. And you're quite heavy user.
*07:55*

**Jason Vallery**: of it. How that stacks up to the national average is this group is clearly ahead of the norm. If we take a look at the US level statistics, about 54% of US adults regularly use AI. And this is fairly fresh data as of November. AI has actually been the fastest adopted consumer technology in
*08:25*

**Jason Vallery**: If you reflect on the landline telephone, it took 75 years until there were 100 million users of it. It took the mobile phone 16 years. It took the internet seven years. And ChatGPT got to 100 million users in just two months from when it launched in November of 2022. Today, ChatGPT has 800 million active users. And when you add in Grok and Gemini and Claude and the other
*08:55*

**Jason Vallery**: There are over a billion people who use these tools on a regular basis, which means one in nine humans on planet Earth are already benefiting from artificial intelligence on a regular basis. We can see that it shifts to the younger generations. This isn't equitably used by all of the age groups. And I think that's a clear opportunity to make sure all of us benefit from what AI has to bring and what AI has to offer.
*09:25*

**Jason Vallery**: AI actually is because it's not just chat box and it's got a long history. It's actually been with us for a while. You know, really at its core, it's a set of mathematic algorithms. It is a process that the industry refers to as deep learning where you can take inputs of data and draw statistical correlations and get outputs that are useful. And the first real commercial example of this was in 2012 when we
*09:55*

**Jason Vallery**: We unlocked the ability to do image and facial recognition. You know, the kinds of systems that are probably part of your doorbell today that identifies the cat or the dog or the person or the car and the kinds of things our phone does to recognize our kids and our parents and be able to tag our photos for it. That's a form of AI. If we continue on the journey, AI started to develop reasoning capabilities and strategy capabilities. And ultimately in 2022, we saw our first chatbot, which gave us an interface into these
*10:25*

**Jason Vallery**: of models and systems. And then in 2024, this is the key big milestone, which is probably underappreciated because it's not something most of us are using at this point, but the ability for an AI system to act autonomously and become an agent and do things for us, it can take apart a problem and execute a long-running analysis of that problem and use tools and come back with results. And what we're seeing now is this proliferation of
*10:55*

**Jason Vallery**: Agents and our agentic future, which is a delegated employee that can go do things on our behalf. And this is where the industry is spending most of its initiative right now. When we look at this then at the big picture lens, you know, chatbots and the way we use them just become the tip of the iceberg of what's coming. Even today, there are systems that you may not think of as AI or actually AI. You know, in finance, 85% of stock trades are made by AI-like algorithms.
*11:25*

**Jason Vallery**: fraud detection and finance logistics maps routing all of these things the
*11:54*

**Jason Vallery**: recommendation engines your social media feed what you consume on instagram or facebook or
*12:00*

**Jason Vallery**: twitter or your netflix recommendations youtube all of those are ai algorithms and the one
*12:06*

**Jason Vallery**: that gives me the most pause and concern is the one we first talked about the global eye there are a billion security cameras and surveillance cameras in use on planet earth right now and the vast
*12:12*

**Jason Vallery**: of those have an AI algorithm connected to it that's watching us and determining what we're doing. And this introduces a whole suite of conversations to have around privacy and governance of this kind of data and who has access to it. Now, how did we get here and how does this continue forward? There's this concept of exponentials. And it's not something humans are well equipped to think about. You know, we think primarily linearly. We think one, two, three,
*12:24*

**Jason Vallery**: 3, 4. But progress in artificial intelligence is mostly exponential in nature. That's 2, 4, 8, 16, 32, 64, 120. Those numbers that double in each iteration. So for another analogy, imagine a piece of paper. And if I was to take that piece of paper that's probably about 0.1 millimeters thick and fold it in half, it'll double in thickness and be 0.2. And if I double it again, it'll be 0.4 and then 8 and 16. And keep doubling that. And if you folded that piece of paper in half 10 times, it's about
*12:54*

**Jason Vallery**: as thick as your hand. Twenty times it's as tall as the Empire State Building. And if you were able to fold it 42 times, you have a piece of paper that would stretch from the earth to the moon. Because these numbers get so much bigger when doublings happen. Obviously you can't fold a paper that many times, but the point here is these laws of large numbers start to add up over time. And when you think about data and compute, all of the recipes that are necessary for this, we're seeing these exponentials. It's driven by physics. The core components in
*13:24*

**Jason Vallery**: the building and AI algorithm or the math, we talked about, these deep learning algorithms, but they have to run somewhere. They run on these supercomputers that are built specifically for this purpose. And those supercomputers get bigger and bigger and faster and faster as time goes on. And they're fed by data, the data we're creating and the data we're providing it. And this is a reinforcing loop. The more data there is, the better the algorithms get. The better the algorithms get, the more compute you have to run on them. And this flywheel, this loop, this
*13:54*

**Jason Vallery**: is what's really propelling AI forward and giving it a set of nearly superhuman capabilities. And this trend line continues. Let's ground us in where we're at today. So if you use AI like I do for your email and tasks and maybe research and search, those kinds of problems, you may not notice how quickly AI has improved, even in the last 12 months. But if you look at the frontier of what AI is, these are the
*14:25*

**Jason Vallery**: really hard problems that we face. The frontier of physics and chemistry and biology, all of these hard domains where there's PhD level researchers trying to move humanity's understanding of these things forward, AI has been a tremendous accelerant for these. What I'm showing are two benchmarks the industry uses. The first one, the blue line, is called humanity's last exam. Clever enough. This is a
*14:54*

**Jason Vallery**: A group that got together and created a way to assess what the frontier models, the most powerful and capable models are capable of as it looks at knowledge and understanding of facts and it assesses how accurate it is against all of these different topics that I alluded to and really the sum of human knowledge. And you can see a very continual progression and how advanced AI systems are getting. And it's not just one model. It's switching back and forth from different providers. It's going from OpenAI to Google
*15:24*

**Jason Vallery**: to Grok to even the Chinese model, Deep Seek. And if we look at the red line, this is the one that excites me the most and gives me pause as well. And this is reasoning. These are those agents I talked about. These models are now capable of what we would describe as novel understanding of problems that humanity didn't even understand before. They're taking these really hard frontier math, science, engineering problems, computer coding problems, and they're spending days and weeks in some cases doing analysis.
*15:54*

**Jason Vallery**: and trying to solve them. And they've been empowered with tools. They can use their own programming languages to write code and do tests and experiments and come back with results. We've gone from a world where this capability didn't even exist in April to OpenAI was at the frontier of this and doing impressive things and creating new research and new science and publishing new papers to the point where we literally doubled in capability just a couple weeks ago when Google released the new Gemini 3 Deep Think capability.
*16:24*

**Jason Vallery**: I mean Google just won the Nobel Prize in chemistry. This is a world that is unprecedented and how are we getting there? This is Moore's law. Some of you may be familiar with this. It's been around for a long time. It's not really a law. It's actually an observation that was made by the founder and CEO of Intel way back in the 1970s. He observed that roughly every 24 months the capabilities of
*16:54*

**Jason Vallery**: of a given computer chip doubled in performance. And that has been an astoundingly accurate observation he made way back then. And what this graph represents is if you look back all the way to the beginning, 1936, when we had our first real computer chips, all the way up to today, there's this very clean line. And that's not because of the way this is graphed. That's actually real data. That's actually the line. And what this represents on the y-axis is for an inflation, a
*17:24*

**Jason Vallery**: How much compute capacity could you buy to do mathematical operations per second or floating point operations per second is what the industry refers to them. So how much math can you do for a given amount of dollars? And it's a exponential line, logarithmic. And so each one of those lines is a doubling in capability. And so over that time horizon, we have a 75 quadrillion increase in how much computational power we can get out of a single chip.
*17:56*

**Jason Vallery**: And there's no sign that this trend is going to stop or reverse. In fact, the opposite is true. The most recent generations of chips coming from NVIDIA doubled in nine months instead of 24. We see this line accelerating, not decelerating. And when you think about that, at each one of these click stops, it's twice the capability that we had. 24 months from now, we'll have twice the computational power than we have today, and we have twice today what we had 24 months ago. That exponential continues, and it's being
*18:23*

**Jason Vallery**: We started off the chat GPTU that you use was trained on the sum of the written knowledge of humanity. All of the books we've written, all of the articles we've written on the internet, Wikipedia, all of the blog posts, the forums, all of the software code we've written, all of that fueled this first wave of artificial intelligence. We use those big computers and those deep learning algorithms to go assess all of that information. But we're entering a new era of artificial intelligence.
*18:56*

**Jason Vallery**: This is real world AI. Instead of training on all those things we wrote down, we're now training on real information and sensors. We're taking all of that video from those surveillance cameras. We're taking all of the weather data, the machine data coming off manufacturing systems. Every kind of data that you can get your hand on and feeding it into these big deep learning algorithms to learn what we can about reality. If you think about a Tesla vehicle, it has 10 cameras on board.
*19:23*

**Jason Vallery**: And every time it's driving, it's recording everything it sees. And all of that data goes in to create one of these models. And it's not just learning about the laws of the road and the cars around you. It's learning about buildings. It's learning about physics. It's learning about nature. It's learning about everything that it can observe as it drives down our streets. And that's going to continue as more and more of the devices we use, the robots that come into our lives, all are recording this information and feeding it into these big
*19:53*

**Jason Vallery**: and as we transition from that type of data to synthetic data, what synthetic data represents is when these models are doing their analysis and they're solving these problems, they're having what I would describe as original thought. They're creating new information and that becomes a flywheel as well where their discoveries feed the training process. So you have all of this real-world information, this synthetic information, and all of our recorded information
*20:23*

**Jason Vallery**: feeding a new explosion in intelligence and a new generation of models that are being built. And then the last key ingredient of this is the one that stuns me the most and it's the infrastructure scale. So we've got really fast chips but what happens when we connect millions of them together? This problem is the opportunity that all of the tech companies and the nation state governments are seizing. What I've got here is an aerial photo from about a month ago of a site in Abilene
*20:53*

**Jason Vallery**: in Texas. It's a site that Crusoe, they're actually a Colorado company, is currently developing. Now, this represents a single computer. It's 120 acres. It is going to be built to do one task, which is to train the next super intelligent AI system. It represents 32 distinct data halls, and it will consume 1.2 gigawatts of electricity. That's 1,200 megawatts.
*21:23*

**Jason Vallery**: This site is enormous in scale. This is space race level of investment and more. And it's not unique. This site in Ebilene, Texas is only one of 22 sites being developed across North America and the Middle East that are at gigawatt scale or larger for this purpose. The electricity grid cannot provide this much electricity. Many of these sites are being powered by natural gas pipelines fed directly to the facility with
*21:53*

**Jason Vallery**: on-site turbine generators powering them. Let me ground you in what this means from an electricity perspective. Longmont, we get all of our power from Longmont Power and Communications, but Longmont doesn't generate its own power. It buys its power from the Platte River Power Authority. And it's a consortium of our communities here in northern Colorado, including Fort Collins, Loveland, Estes Park, and all of the rural areas in between. And the Platte River Power Authority provides electricity for
*22:23*

**Jason Vallery**: 660,000 residents and 150,000 households. And if we reflect back to the hottest day in July of this year when it was probably 105 degrees outside and we all had our air conditionings on, and it was the middle of the day and all of the businesses were open and all of the manufacturing we do was humming, Platte River Power Authority was producing 720 megawatts in that moment. And I just told you that single computer takes 1,200 megawatts.
*22:53*

**Jason Vallery**: The facility north of Fort Collins, if you're driving up to Cheyenne and you look off to the left off I-25 that I've gotten that picture is called Rawhide Unit 1. It is the largest power generation facility in the Platte River system. It is capable of producing 280 megawatts. To power that single computer in Texas, you'd need five of those running 24/7, 365 at peak production. That's the scale of what these computers are consuming. And that's what takes us to this next wave of superintuitive.
*23:22*

**Jason Vallery**: This amount of power, these incredibly powerful chips running on top of them, and this immense data trove being fed into it. And that's triggered a global arms race. Everyone wants in on this game. Right now, there are committed 300 gigawatts worth of projects across North America and the Middle East. And we don't even really know what China's up to because they're not very public about it. And we're pretty sure they're doing the same thing.
*23:52*

**Jason Vallery**: is referred to as the $7 trillion bet. T trillion. Right now, between now and 2030, the expectation is $7 trillion in CapEx. This is being funded by tech companies, by energy companies. It's not being funded by nation states because they see what kinds of economic benefit exist if they're the ones to control a superintelligent system. They don't make bets that don't have an ROI. They're pretty sure that
*24:22*

**Jason Vallery**: Putting this much money in the game is going to give them a return on that investment. And here's how it does it. Robotics is evolving very quickly. So if you have a super intelligent AI and you've got these humanoid robots, my wife asks, why do they have to look like a human? Well, they have to exist in our world. They can go up and down stairs and go through doors and use tools that were designed for our hands. They need to live with us. And that means they kind of have to be physically like us.
*24:52*

**Jason Vallery**: And these robots are incredibly capable even today. And the biggest challenge that has been holding robotics back for decades is not the hardware so much as the software, the control systems, the brain. It's hard to write software and handle uncertainty in your environment and deal with dynamic circumstances. But that's exactly what AI does really well. And so you've got companies who are taking these AI algorithms and embedding them into the robot.
*25:22*

**Jason Vallery**: to control their movements, their actions, their decision making, and be able to adapt to a very dynamic environment. And that's yielding some incredible results. I want to show you some videos from this week. There was a trade show where two key robotic manufacturers demonstrated. This white one is from figure robotics, and this more gold-colored one is from Tesla. And oh, is it not playing? Oh, there it goes. And they run like us. They have fluid movement. This is real robots this week demonstrating their movement.
*25:52*

**Jason Vallery**: And then let's look at their hands. They have very, let me get this to play right, they have fine motor control. They can crack an eggshell. They can manipulate very tiny objects. These hands have become incredibly capable. So we're at a moment in time where things are going to get really weird. We've got companies who say that they're going to go into mass production of robots like this next year. They're going to
*26:22*

**Jason Vallery**: start manufacturing these at scale as soon as March. That's happening now. And they're going to be in our world and we're going to have to accept that they're our neighbors and they're being used around us. What does this look like? This is a convergence moment where these super intelligent AI systems are embodied in physically capable humanoid robots. And when these things hit mass scale, it creates what I'm describing the synthetic superhuman. It's physically more capable than us.
*26:52*

**Jason Vallery**: It can work 24/7 without getting tired. And it has superhuman cognition and understanding of the environment around it and has a full sum of all knowledge because it's connected back to the cloud and the full set of AI capabilities therein. And when you get to this moment in time, the bottleneck of economic productivity is no longer human labor and human talent. It is the raw energy, the natural resources, the raw materials, and the choices we make as human to gut
*27:22*

**Jason Vallery**: humans to govern how these things are used. This moment in time by sci-fi writers for a long time has been referred to as the singularity and they've often described it as an inevitable moment. I don't know when we get here, but what this is going to look like is a fundamental transformation of our economies, governance, and really even human purpose. I worry, a lot of people ask,
*27:52*

**Jason Vallery**: If robots do the work, how do we survive? How do we eat? How do we pay our bills? These are real challenges we're going to have to start thinking through and face. The economic lens, the way the industry would describe this is that when you have humans out of the loop in our cost to produce goods and services, it's very deflationary and everything becomes very, very, very cheap and inexpensive because we can produce all of it that we want. And you might change governance to start thinking about concepts like universal basic
*28:22*

**Jason Vallery**: income where we're providing for our citizens. Some even describe a world of universal high income. You know, a world where the poorest person on planet Earth today has a better quality of life than the richest person on planet Earth today because of the abundance we can achieve by enabling automation to do all of the work that we do for us. I don't know how this plays out. I'll say Bill Gates has a kind of famous
*28:52*

**Jason Vallery**: here that I reflect on in terms of timeline. He often says that we overestimate dramatically what we can accomplish in two years, but underestimate what we can do in 10. And I feel like that's the right window to be thinking about how this starts to impact us. And so, you know, with those facts and figures in mind, I want to talk in transition a bit about what it means for us in this community. Myself, along with a few other folks, have been talking about this quite a bit.
*29:22*

**Jason Vallery**: at the forefront of this for a long time, so anyone who knows me knows I don't shut up about this. But we want to start a bit of an initiative to continue this dialogue. And so we're calling it the Longmont Next Wave Initiative, and we'll have some more collateral about it towards the end. But the way I frame this is to think about the five pillars of our community which are most important and most impacted by this. And so I want to walk through each one of those and talk about how I see this unfolding and what our opportunities are. But I first want to ground us in a set of
*29:52*

**Jason Vallery**: I think in Horizon 1, 2, 3, all the time in my life, and I'll establish them here. Horizon 1 is the here and now, the capabilities that these systems already give us, and we make no assumptions about forward progress on them. We already see patchy disruption. We already see AI systems that are writing for us. We certainly see it in the software industry because it's creating code for us. It's planning. It's our admin. We're using it
*30:22*

**Jason Vallery**: in this way and there already have been jobs impacted by the tools that exist today. And as we continue forward, when we get to Horizon 2, what we're saying is that there are true structural changes and whole workflows that we do in KnowledgeWork have changed and jobs have had to reorganize around this concept of AI agents doing the work for us. They can act. They don't just chat. They can act on our behalf and do things, use tools,
*30:52*

**Jason Vallery**: And then at some point this will continue inevitably to that horizon three moment I described where suddenly we are in a state where the only constraint of productivity and economic growth is the energy and natural resources. And this is our post scarcity future. And so across these three horizons we have to be thinking about how we want to prepare Longmont for that. Let me give you a real stat that came out of McKinsey. McKinsey is a consulting firm who does a lot of
*31:22*

**Jason Vallery**: of work with Fortune 500 companies and thinking about systems and job structures and automation and how to approach some of the challenges of running an enterprise scale company. And McKinsey has a bunch of consultants that think about this a lot. And so they went out recently and did a study. They looked at the Fortune 500 and they looked across all the industries from healthcare to finance to energy to technology. All of the 500 largest corporations in America
*31:52*

**Jason Vallery**: and they looked inside of them and said, "What are all the jobs? What do those jobs do? What are the tasks that those jobs do?" They reported out in this study that the capabilities of the systems we have now in Horizon 1, again, they don't get better than what we already have today, are already capable of automating 57% of the tasks that knowledge workers do. We're not in a moment where we're waiting for the technology to arrive. We're waiting for the corporations to
*32:22*

**Jason Vallery**: to implement them. And this is going to go one of two ways. Some will choose to use this as a lever of economic prosperity, where we'll enable our employees to do more, and they'll get more done in a day, and they'll be able to manage these fleets of AIs to have more impact and create more goods and create more services. And then there are other companies who will look at this as an opportunity to say, "I need fewer employees. I can restructure the way I manage this work." But regardless of how this goes, it's going to have economic impact to
*32:52*

**Jason Vallery**: to us and it's going to be a stressor for us.
*33:22*

**Jason Vallery**: Let's talk about this in the frames that I mentioned.
*33:25*

**Jason Vallery**: Let's start with education.
*33:27*

**Jason Vallery**: I'm also a dad.
*33:30*

**Jason Vallery**: My kids are in the audience.
*33:31*

**Jason Vallery**: I have three kids here.
*33:32*

**Jason Vallery**: I have a fourth grader who's at Central Elementary, a sixth grader who's at Westview,
*33:34*

**Jason Vallery**: and my son graduated from Longmont High School recently, and he's over at CU Boulder now studying
*33:39*

**Jason Vallery**: computer science.
*33:44*

**Jason Vallery**: Not sure he's actually going to have a job in it, but we're going to figure that out.
*33:45*

**Jason Vallery**: And he's following my spits.
*33:50*

**Jason Vallery**: So that was my background. I was a software developer, right? And I want to bring this with a real example. My daughter in sixth grade. The initial reaction I think most parents have around AI is we should ban it. We shouldn't let them use it. They're just going to use it to cheat. But she was struggling with math. Sixth grade math is hard. She didn't get it. She was getting poor test scores. She was really having a hard time with it. And I don't get it either. Sixth grade math is really hard. It's fundamentally different than
*33:51*

**Jason Vallery**: any math I ever learned. So I really wasn't able to help her. But we sat down and took a picture of her homework and we shared it with ChadGPT. And it's got this study with me mode. When you enable this, it acts as a personalized tutor and it has a conversation with you. So she sat there and she spent the evening working with ChadGPT and learning. And then when she took her NEST math test, she went from not understanding it at all to literally getting the highest score in her class. I'm stunned by how effective it was because it was a personalized tutor that met
*34:21*

**Jason Vallery**: where she was at. It understood the questions she was asking, and it tailored the answer to what she needed. That's an empowering technology if I've ever seen one. And I think about it in the lens of the teachers. The teachers, the value we get is the time they spend with our students. When they're doing administrative work or grading papers, that's time they're not spending with our kids. If our teachers can leverage this in that way, that creates those human connections, which are most important between our students,
*34:51*

**Jason Vallery**: and their educators. I think the here and now is that. We need to figure out how to get these tools in the hands of our students to empower their learning and to enable their teachers to bring that human connection to that. As we move forward into this agentic future, though, the future changes. And this looks like a different set of skills that we need to teach our kids. You know, I think about these agents, and I really think about it as you become an architect. Instead of the doer, you describe what's needed, and you manage a fleet
*35:22*

**Jason Vallery**: of employees or agents to do tasks for you. This is a skill we're not equipping our children with. And it's a skill that's going to be necessary not just for our kids, but ourselves as this continues forward, is managing these systems. And then when we get out to our horizon three, this is when education changes fundamentally. And it's not about preparing our kids for a future world of work and a career. It is about equipping them to be what is uniquely human and changing what we're teaching
*35:51*

**Jason Vallery**: and ethics and debate and creativity, those skills that no matter what AI is capable of, it will never replace us. This is the same conversation around local businesses and our local economy. I use these tools in a variety of ways, but they help me bring chaos to the noise, taking data and bringing structure. We want to get our local businesses doing the same thing. We think we need to get these tools in the hands
*36:22*

**Jason Vallery**: of these local businesses to do these kinds of things to make their operation more efficient because they don't have the staff that a big enterprise company would have to do these different marketing tasks and so forth. So I think there's a real short-term opportunity. And again, even in that agentic future, teaching our local businesses to think of these as employees is a key component of how we can maintain that local economic prosperity. Like I think of an example, if you could even be a plumber and if you have a team of agents on your behalf, think about how much more work you could do.
*36:51*

**Jason Vallery**: It could be ordering your parts for you and scheduling your customer meetings or your customer client calls. It could be navigating your vehicles. It could be maintaining your inventory. All of those things which are time-consuming for us as we offload those to AI, it frees us up to have more impact. And this will transcend all of us. It will impact all of us in all of the things we do. And long-term, what I want us to think about in terms of local business and local economy is how we capitalize on the human premium. I think the things that will always matter
*37:21*

**Jason Vallery**: As I said, our human connection, human presence, and investing in local businesses that prioritize that. Experiences aren't going to go anywhere. We're still going to want to enjoy going out to a restaurant or going to a museum. These are the things that will matter no matter what, and investing in those makes sense now. In the lens of our community and our government, Longmont is a fantastic city. I love it here, and we have a great city government, but they're going to be faced with some difficult decisions, and it's
*37:51*

**Jason Vallery**: It's already happening. There's no shortage of vendors out there that are trying to sell municipal solutions to things like policing and surveillance and HR and city planning. These are AI driven solutions being sold to municipalities all over the country. And our government is no different. They're going to have to set up a value system of how we maintain Longmont residents' data, our privacy, how we make decisions. It's imperative the city get ahead of this. And as the time continues, they'll find more ways
*38:21*

**Jason Vallery**: that AI will impact city decisions like traffic management and power grid planning, all of the paperwork and bureaucracy that are necessary for a city government like fines and permits and all of those things will be touched by AI. And it's important that we establish a framework around how decisions have humans in the loop and that we can apply empathy to our residents when those decisions are made. And lastly, as we get into that third time horizon, one of the things I love about long model
*38:51*

**Jason Vallery**: the thing that continues on into that future. We've invested heavily in our parks and our open space and this museum and our rec centers and our public art and all of the things that make it wonderful to live here. And my hope is that Longmont continues to invest in those things because that's the thing that's going to keep us all together and the thing we're going to get the most value of. So that's kind of the three horizons across the city. Technology and workshops. What I mean by this is that I see a digital divide. And there's been a digital divide.
*39:21*

**Jason Vallery**: the haves and have nots of access to technology. And AI is going to widen that gap. There's a lot of uncertainty and fear about these technologies and hesitation to adopt them. This room seems very forward thinking, but that isn't necessarily representative of our entire community. I worry very much about what can happen when we have a set of individuals who are leveraging these to maximize their impact and a set of individuals who ignored them and are left behind.
*39:51*

**Jason Vallery**: and we want to partner with folks like LPM who's recording this here this evening to make sure content and collateral is getting into our bilingual communities and accessible to everyone in Longmont so they understand how they can benefit from this technology like the rest of us. And in the long term what does this mean? I think that AI empowers the maker. It allows us to become a medium for our imagination. It is another tool in the maker's tool belt. It'll solve
*40:25*

**Jason Vallery**: and can be applied in unique ways to realize our imagination. And I think the most important pillar we have to focus on is resilience. This is the one that has the most kind of scary moments for me. I think in the short term, there's a lot of denial about AI. There's a lot of politics behind it, and it's been politicized. And this has created a very difficult
*40:51*

**Jason Vallery**: and we start now and this conversation here in this auditorium is the first step of having these conversations as a community and talking to our neighbors and making them aware of what's coming and preparing them for it. And then as this shifts and we start seeing real
*41:35*

**Jason Vallery**: world impact in our community jobs changing financial stresses of our neighbors this is the kind of thing that can fracture a community there's going to be this clear split of the ai winners in our community and displaced workers who are struggling to find their place and we have to mobilize our local networks our nonprofits our civic groups and really provide a support structure and safety net while we work through this transition to get to that horizon
*41:51*

**Jason Vallery**: 3 utopia I see for all of us. And then when we get there, that's about finding our purpose. I worry about this for myself. I find a lot of meaning in what I do and my purpose wrapped up in my work. And if I'm not economically valuable, what is my purpose? And we're all going to go through this existential question of why am I here? What do I do? How do I drive meaning? And that's where we come together as a community.
*42:22*

**Jason Vallery**: where we start investing in our time and exploring nature and the arts and our hobbies and community groups and connection because I've said it a bunch of times but I got to keep reiterating it that's what makes us human and keeps us together through this incredible moment. So like I said we're going to try and kick off a little bit of an initiative and see where it goes and who we can get to participate and starting these conversations working some with some of our existing established community groups like the school district and the
*42:51*

**Jason Vallery**: and Rotary, LPM, all of the makerspaces, the city, and really see if we can get a dialogue going about being prepared for this wave that's going to crash over the entire globe, but let's have a focus on what happens here at home. We'll have a handout, and I'll put this QR code up at the end as well, but this will take you to a website where there's a much more in-depth survey to gauge your sentiment around the topics I just described and how you see this unfolding for Longmont.
*43:21*

**Jason Vallery**: and a clear call to action to continue the dialogue and get engaged. We'll have our next meeting in January, and we hope we can get as many of you there as possible. So with that section, I'd like to invite Justin back on stage, and we're going to sit and have a conversation in a little more candid way about what the risks, opportunities, and unknowns are as we work through this together.
*43:51*

**Justin Veach**: The AI firehose, right? That was a lot of information. Indeed. Hello? Hi. I'm here. I kind of feel I kind of had to scrape myself up off the floor a little bit there. Yeah. With the robots and the... Intense, isn't it?
*44:35*

**Jason Vallery**: That's a lot. So thank you. That was very well delivered. Thank you. You've obviously been thinking about this for a while. Yeah. I came home from my first meeting with OpenAI in 2017, and I remember sitting next to my wife just mind-blown, having had these conversations with some of these researchers who saw this future that I wasn't yet awake to. And ever since that moment, I've been telling everyone I can and thinking about it.
*44:51*

**Justin Veach**: about this nonstop. It's really consumed me for a number of years now. It is rather all-consuming. You know, there are a lot of folks out there these days who know a thing or two and have some opinions about AI, but we invited you to join us because you're one of our own. You live here in Longmont, and you could live just about anywhere. I could, yeah. I mean, you could probably live on your own private island at this point. I don't know about that.
*45:21*

**Jason Vallery**: I will say that there would be certainly benefits from a career perspective to be based in Silicon Valley or Seattle and it's meant a lot of maybe sacrifices in the form of travel to maintain my home here and you know opportunities that I haven't been able to capitalize on being based here but it is my home it is such a great community I love it here my family's here as I said I grew up here and the people here are great like one of the things I reflect on when I go like to San Francisco and I'm in the Bay Area or Seattle or really you know for my
*45:51*

**Justin Veach**: I've traveled all over the world is when you walk down the street and you smile at a stranger they get super uncomfortable and look the other way when you're a long mud on Main Street most of the time they smile back and nod unless they recently moved here it took it took me a while I'm smiling to people on the street yeah best people in the world yeah right okay I think so yeah how is it that you came to occupy
*46:21*

**Justin Veach**: this position you're now in.
*46:51*

**Justin Veach**: What was the path like?
*46:54*

**Justin Veach**: I mean, you grew up locally.
*46:55*

**Jason Vallery**: Went to Longwood High.
*46:58*

**Jason Vallery**: Yeah, Longwood High class 2000 was great.
*47:00*

**Jason Vallery**: I was super into computers as a kid.
*47:02*

**Jason Vallery**: I had some really great opportunities and mentors early on.
*47:05*

**Jason Vallery**: And when I graduated, I was already writing code.
*47:09*

**Jason Vallery**: I had my first job as a software developer when I was 18.
*47:12*

**Jason Vallery**: And I jumped into the industry.
*47:16*

**Jason Vallery**: You know, I dropped out of college when I was 18.
*47:17*

**Jason Vallery**: James, don't do it.
*47:20*

**Justin Veach**: Right down the street.
*47:23*

**Jason Vallery**: Yeah, right down the street.
*47:24*

**Jason Vallery**: And I worked full time in the industry and I made some really great choices along the way in terms of pivots and where I saw things coming. My wife reflects on this a lot where she says, my superpower is anticipating what's coming. And because as you map through that career, it was always this moment in technology where I saw the trend and I was early to identify the trend and I shifted my career to focus on that. And I started off and made a pivot towards the cloud and cloud computing.
*47:26*

**Jason Vallery**: I landed in Microsoft in the very early days of that and I rode that wave and then I made the pivot to AI and I'm riding that wave now and so I've been just very fortunate of being in the right place in the right time and making the right bets and it's taken me on quite a wild ride it's been fun. And you're not even close to being done yet. Well I mean the tsunami is. Two to ten years and some sometime along that time horizon we'll all be retired maybe I don't know we'll see what it looks like. We'll see but you'll be here. I'll be here. That's right.
*47:50*

**Jason Vallery**: That's great. That's great. I thought we'd just go over some basics. What's a Zib? Zebabyte or Zetabyte depending on how pedantic you want to be about it. But if you think about this as orders of magnitude of data. Your laptop probably has a one terabyte hard drive and a terabyte is 1,024 gigabytes, which is another term you might be familiar with. Well, 1,024 terabytes is a petabyte.
*48:20*

**Jason Vallery**: 1,024 petabytes is an exabyte, and 1,024 exabytes is a zettabyte.
*48:48*

**Justin Veach**: Or a zip. Do you call it a zip?
*48:58*

**Justin Veach**: Yeah.
*49:00*

**Justin Veach**: Okay.
*49:01*

**Justin Veach**: Yeah.
*49:01*

**Justin Veach**: All right.
*49:01*

**Justin Veach**: So we have to start thinking bigger.
*49:02*

**Justin Veach**: Or some types.
*49:04*

**Justin Veach**: Zips.
*49:05*

**Justin Veach**: So you're optimistic, but this really could all go very wrong.
*49:08*

**Justin Veach**: It could.
*49:15*

**Jason Vallery**: There's a lot of things to worry about. I think a lot of people immediately turn to the Terminator movie and they're like, oh my gosh. I don't know about traveling back in time and stuff because that's a major part of Terminator. The robot piece. I saw those robots and thought, wow, that's scary. I don't think the Terminator movie is the way this plays out. The thing about humans uniquely, or at least my perspective, is that we have free will. We have goal.
*49:16*

**Jason Vallery**: and motives. And there's nothing in math algorithms that imply to me that it has goals or motives or free will. I think we're safe. But what I actually worry about is these incredibly capable systems in the hands of malicious actors. This is where the real risk comes in. You know, you think about, I mean, even you've probably all seen a drone show that the Innovation Center puts on with our high school kids. And, you know, when you look at something like that, these autonomous systems, you know,
*49:46*

**Jason Vallery**: there aren't hundreds of high schoolers individually flying those drones. They're being flown by an algorithm. And that algorithm in the hands of a malicious actor in those drones, which were very accessible to the district at a very affordable price, could be repurposed for malicious intent. And you can think about that in a variety of ways. You can think about it in the cyber attacks and attacking our systems of banking and governance. You can think about... Which is happening. It's already happening, right?
*50:15*

**Jason Vallery**: You can think about what nation states get in their ability to build autonomous weapons. I mean, not to scare you, but the U.S. has already been showing the autonomous fighter jets that we have, the autonomous attack helicopters. The capabilities of autonomous weapons in the wrong hands are frightening. And so putting that in the front of my mind is something that I very much worry about. I think that, you know, how this plays out really is a nation state level cold war. What's happening right now
*50:45*

**Jason Vallery**: now is clearly the Chinese and the Americans are at it. And the Chinese are building the same level of very complicated systems and autonomous weapons. And they have a path to superintelligence just like we do. And the math and all of the understanding how to build these algorithms is out of the bag. And all of the infrastructure necessary is a construction problem. And so it's a bit of a space race. It's a bit of a cold war happening right now. So if it's a race, what happens if you get there? What does it look like to get there
*51:15*

**Jason Vallery**: first. Well, you know, I think it is that moment of mutually assured destruction that we're aiming for, like that we've had this great balance of power because we both have it. You know, I think if you get there first, there's a potential world of domination that can happen if the other side doesn't have it. You know, there's no signs that it's going to be a wide time gap. The Chinese have been at the frontier of this and leaped frog back and forth with the U.S. labs. I think the thing that I worry about the most there is
*51:46*

**Jason Vallery**: the motivations behind it. In China, it is a nation state endeavor. The Chinese government is behind it and they have a clear purpose. In the US, it's being driven by the tech companies and the tech companies are there to make a return on their investment. And so they're building AI systems that look very different. They're building models that predict or that do deliver generated videos that, you know, consume your Instagram feed. Clickbait. They're using it to generate content that will consume us and glue us to our
*52:15*

**Jason Vallery**: our screens. And so that's just a fundamental different approach how all of this is coming to play. I'd also say that, you know, in China they've got a much more unified approach. Where here we've got a bunch of competing tech companies who are not pooling their resources and their understanding because they're competing with each other. And, you know, there are a lot of folks in the industry who have been saying for a number of years that this should have been nationalized. That we should have taken all of the leading researchers out of these industry and out of these tech companies and give them the unlimited
*52:45*

**Jason Vallery**: resources and fund this like we did the Manhattan Project way back in the '40s and treat it that way. That hasn't happened. It's too late for that. Is it too late? I think it's too late. I think we already see the path and it's going to be here before long. So the race is really between a corporation and a nation state like China or China basically. It's also a race between corporations. There's a lot of money on the line to be there first with the most capable systems and the most users using them.
*53:16*

**Jason Vallery**: I'm not sure what it means to be there first though. It's all degrees of having it, right? I mean, there isn't, I guess it's all about implementation. You know, that's right. Like when you look at any transformative technology, one of the things that's often referred to is there's really only ever two major players are winners. If you think back across all of the innovations that have happened from computers, there was Microsoft and Apple from mobile phones. There was
*53:45*

**Jason Vallery**: and Android. If you think about search, there's Google and kind of Bing. Always there's kind of two players and then a long tail of players. And it's about user acquisition. It's about being there first with the right systems that get implemented. OpenAI had that first mover advantage, has that first mover advantage, and that's incredibly beneficial for it because it's got this established user base. It's hard to disrupt that and dislodge an incumbent.
*54:15*

**Justin Veach**: So if China somehow manages to sort of outplay all of these other, well,
*54:46*

**Justin Veach**: chat GPT and Google and stuff, what could that mean?
*54:54*

**Jason Vallery**: I think there's two lenses to apply. There's what does it mean from the higher level autonomous systems,
*54:59*

**Jason Vallery**: robotics, autonomous weapons perspective, and then there's the commercial perspective of how those things are taken to market
*55:06*

**Jason Vallery**: and used by our companies and used by us as individuals. From the nation state perspective, there's clearly a divide. They look at this as a completely isolated tech stack. They don't want dependencies on US technology. This was actually very recently kind of debated out in the public press where initially GPUs were being shipped to China. Then there was a limit in terms of the capabilities they could have. And then we had an embargo and said we couldn't sell them to China. And China decided,
*55:14*

**Jason Vallery**: They needed to not be dependent upon America, and they went their own way, and they've developed their own chips and their own software because they want to have their own ability to influence their own destiny. They want to proliferate that. They want to share that with other countries because if you're dependent upon
*55:44*

**Justin Veach**: It's a closed system, and they want to add people.
*55:59*

**Justin Veach**: Exactly.
*56:02*

**Justin Veach**: They want to expand that closed system.
*56:02*

**Jason Vallery**: Yeah, exactly.
*56:04*

**Justin Veach**: Weird.
*56:07*

**Jason Vallery**: Yeah.
*56:08*

**Jason Vallery**: Now, on the consumer side, you've obviously got the example of what happened with TikTok recently, and clearly,
*56:08*

**Justin Veach**: We will have some concerns around the data privacy elements of that. And you can imagine that it's not in any of our interest to be sharing all of our data back with China. So we'll see how that unfolds. But that's a question for our governments to decide. So let's talk about energy, the power that's required to run these data centers. It does seem like some kind of race against time that, you know, we're building these energy suckers at an alarming rate with the
*56:14*

**Jason Vallery**: that we will develop some kind of intelligence that's going to solve our environmental issues or dependency on fossil fuels or whatever. Is that likely? You know, I'm optimistic. You know, certainly what you've observed is that the tech titans, all the big tech companies have backed off their climate pledges because they're not going to deliver on them. No one's holding their feet to the fire either.
*56:44*

**Jason Vallery**: You know, the technology is not yet mature enough to generate the amount of electricity that these systems need, and that's just a fact. And so we're pivoting and we're going back to what we know and what we can deliver at scale, and that's fossil fuels, that's natural gas. But the argument goes that when you have a super intelligent system, it can help unlock all of those climate opportunities we see. And there is real meaningful progress with small modular reactors. There's fusion that's actually net positive energy happening.
*57:14*

**Jason Vallery**: There's opportunities to deploy this compute capacity into space and leverage solar. So there's a ton of investment. And one of the things I think about that gives me excitement here is that this demand for energy is what fuels the investments in the renewables. And so more money is flowing into these alternative forms of energy than at any time in history. And they're all already showing really promising results. They're not ready to be operationalized at scale to deliver gigawatts to Texas, but they are
*57:44*

**Jason Vallery**: at a infancy where we're seeing real returns. So I'm optimistic that what we get out of this is actually a better climate future while we suffer some short-term pains. And those gains will be, well, hopefully, maybe not exponential, but they'll be... Well, I mean, if you deliver on the promise of fusion, that provides unlimited and abundant electricity at basically zero cost. So, you know, there is a future world where energy becomes free. That is a...
*58:14*

**Jason Vallery**: It's an incredible moment to think about, but it's not necessarily that far off.
*58:44*

**Justin Veach**: Well, you know, we could spend a lot of time on the dystopian aspects of this and how it could go wrong, but let's go into some of the more rosier, the rosier picture.
*58:49*

**Justin Veach**: The highlights.
*59:02*

**Justin Veach**: And, you know, like the benefits on health and general well-being.
*59:02*

**Jason Vallery**: Yeah.
*59:07*

**Jason Vallery**: I mentioned this briefly, and I said that Google just won the Nobel Prize in Chemistry.
*59:09*

**Jason Vallery**: and it was a fascinating moment. They used a what's referred to as a narrow AI, an AI system built for a specific task to do protein folding. When you think about what a researcher in biology or chemistry has to do is they might have an idea of a chain of amino acids that they want to synthesize in the lab and then get the characteristics of it to see if it's a useful molecule that results. And the process of doing that is incredibly labor intensive.
*59:13*

**Jason Vallery**: It takes from one chain of amino acids and a set of experiments in a wet lab, you know, potentially a human in that lab, many, many years of effort to synthesize that molecule. And what Google did was they took all of the data we have from all of these experiments and they ran them through a deep learning algorithm. They created a predictive model and then they created all the possible amino acid chains, every single one of them, and then they simulated them all. And what they
*59:43*

**Jason Vallery**: What they instantly did is removed that step of discovery. Because it's no longer necessary to test your hypothesis in the lab. It is now a known solution. They can go look up in a database. If I chain these amino acids together, this is the result in protein and compound. That moment fundamentally changes things like drug discovery. You know, there's real world implications to this that are happening now in cancer and Alzheimer's research. We will see new novel drugs come to market in
*01:00:13*

**Jason Vallery**: in the near future that cures many of our ailments and our diseases. There's a futurist who I will recommend from a reading perspective in the follow-ups named Ray Kurzweil. And he has a book called The Singularity is Near. And he spends a lot of time talking about healthcare and medicine and the way it'll impact us. And he has a quote. And his quote is, if we live to the year 2030, we become amortal. And amortal means that we no longer die of natural causes.
*01:00:43*

**Jason Vallery**: We've cured all of humanity's diseases and ailments. The only way that we die is because of blunt force trauma. Getting shot or hit by a bus, it's still impactful, but we're not going to die of natural causes. And that's the perspective that many are starting to believe as these discoveries become real. I would also point to access to healthcare. Like you think about these image models and the ability to analyze radiology. You think about robots that could
*01:01:13*

**Jason Vallery**: and potentially be a superhuman doctor or clinician. It provides universal access to the world's best doctor. We'll have that kind of ability at our fingertips. I mean, heck, I already used that. My wife got some test results yesterday. The first thing I did was I went and ran it through AI and said, help me understand this, make sense of all of this. That's the future we live in with medicine is how it accelerates our care and makes us, you know, aware and
*01:01:43*

**Jason Vallery**: solves all of these new challenges. I'm very excited about what it means for healthcare.
*01:02:13*

**Justin Veach**: Wow. Okay.
*01:02:21*

**Justin Veach**: But you're not overly concerned about robots taking over the world?
*01:02:27*

**Jason Vallery**: I, you know.
*01:02:31*

**Jason Vallery**: No. Okay.
*01:02:32*

**Jason Vallery**: I mean, you know, it's a non-zero probability, right?
*01:02:32*

**Jason Vallery**: Right, non-zero.
*01:02:36*

**Jason Vallery**: You can't rule it out, but I, you know, I think, you know, it is, you know, it almost turns into, like,
*01:02:37*

**Jason Vallery**: this spiritual question of free will because what I see is a math algorithm that is taking an input and creating an output. I don't see it having its own free will and motives. And ultimately, that's what it takes for it to turn against us. So I don't know. We just have to upload some motives. Yeah. Right. Anyway. Then that's the human in the human. That's the human actor using it malicious ways. And we have to put the controls in place to prevent that. Let's talk about abundance.
*01:02:42*

**Justin Veach**: where everything is available. Production is somewhat, somehow, I mean, barring limitations in terms of environmental resources, that sort of thing, energy. Things are cheaper. We don't have to work. What does this look like? What does this future look like? I think to ground it in real economic principles, you know, what, what, you know, most of the
*01:03:14*

**Jason Vallery**: the tech industry is pointing to is GDP per capita. Ultimately, the measure of AI success is what is our gross domestic product produced in goods and services per person living here. This will be an accelerating trend line. It won't be a moment in time, but ultimately what you're talking about is being able to deliver more with fewer humans in the loop. It impacts every industry in positive way from agriculture. We already have robotic farming.
*01:03:42*

**Jason Vallery**: We have robotic systems doing harvesting. We have robotic planting. We have robotic crop harvesters. Like all of that is already happening. And so that creates abundant food in the food supply with fewer humans in the loop. And you apply that same mentality to every business, every industry that produces the goods and services that we consume, and we get more and more with less and less effort. And ultimately that, regardless if you get to the point where humans have
*01:04:12*

**Jason Vallery**: No economic value will continue to be the trend line. Things become treaper. Things become deflationary in nature because it costs less to produce them. You look at those humanoid robots and you might think, oh, that's going to be incredibly expensive. But, you know, current estimates are the bill of materials is somewhere around $20,000 in today's goods. Now, if you can imagine an employee that works 24-7, 365 that only costs a one-time $20,000 and how many of those you can build and how you
*01:04:42*

**Jason Vallery**: you can purpose them to useful economic work. Things become a lot cheaper. But we do live in a finite, I mean, resources are finite. Yeah, I mean, that's where the governance part of this comes in, right? You've got a finite amount of natural goods. There's a copper shortage on. I was just reading about this, that we're going to slow down some of the build outs of AI because there's not enough copper. And that means we have to make decisions around how do we mine, where to meet,
*01:05:12*

**Jason Vallery**: How much of these resources are we willing to extract from the earth? Those are real decisions that humanity has to face and make. That's our role. Robot miners in outer space. Robot miners on asteroids. We'll ship them up there and we'll harvest the copper from the asteroids. I think that is a science fiction future that'll turn to reality eventually. But in the short term, you can imagine mining is another industry that will absolutely be hit by automation.
*01:05:42*

**Jason Vallery**: How about my job? Well, see, that's the thing. You're connecting people. You're bringing us together in this forum, in this space. These are the uniquely human experiences that don't go away. Yeah, you guys don't need me. You guys could talk. A chatbot could totally do this, couldn't it? You wouldn't be as entertaining or as connecting. It's true. That's probably true. Okay. Let's see. What else do I got? Okay. How about, what about,
*01:06:14*

**Jason Vallery**: What about art? What about a chatbot that can write a really great poem? Or paint a painting? Or what have you? My son's a trombone player and I like to play music too. And actually my whole family, we're all musicians. And I think about this, right? Like, I don't think I ever want to see a robot play the trombone. I think that's a uniquely human endeavor, right? I mean, I think, I will say to flip the coin a bit, there's been some recent AI generated
*01:06:42*

**Jason Vallery**: And it's actually really catchy. But setting that aside, like from a human connection of art, like you're going there because the art conveys emotion, it can conveys human experience, and you're going there to connect with the artist and to consume their perspective and their talents. I really appreciate live music, and I don't think that'll ever be something I want to be produced by a robot. Amen. Amen. I'm in full agreement with you.
*01:07:12*

**Justin Veach**: Well, I, you know, I want to, I have a feeling that we have some folks who might have some questions for you. Am I wrong about that? I'm probably wrong about that. You probably, you guys don't have any questions about the future AI or robots or, do we have questions? Yeah, I think we do. So we're going to run a micro, Megan's going to run a microphone around. So if you raise your hand, we will find you. Yes, here we go.
*01:07:41*

AI is an important component in the defense industry. And I'm wondering what your perspective is on building an ethical component into AI and how your mention of China being a nation state versus our defense companies, which are for profit. And I'm wondering your perspective on that.
*01:08:09*

**Jason Vallery**: Yeah, I mean, this is a tricky one. I mean, the capabilities of these systems, I think, have caught the defense industry even off guard. You know, it isn't prepared for this any more than the rest of us. And so there's a lot of conversations going on around how to incorporate these and how to make use of these technologies. How this unfolds, I don't know. I worry about it very much. You know, one thing I can point to is that the government has started to take
*01:08:38*

**Jason Vallery**: this very seriously. There was a White House executive order in the last couple of weeks that was referred to as Project Genesis. I think it was described by the White House as Manhattan Project 2.0. And it brings together the Department of Energy. It brings together the tech industry. And it provides resources to do research on this front. You know, our government was going to have to be very careful
*01:09:07*

**Jason Vallery**: We are very careful in how these things are used. It provides that just next escalation that has been an arms race since two warring tribes found the bow and arrow. And this is another version of that that we're going to have to deal with.
*01:09:37*

**Tim Waters**: Hi. So I have a couple of questions and a statement actually that I don't know if you're aware that China has been putting online renewable energy in 2024 they put on line more renewable energy than the US has in the whole history of the United States and of course that is in preparation for these centers but
*01:10:06*

**Tim Waters**: And meanwhile, we're cutting down our support of renewable energy. I don't know what you are drawing from in the history of mankind that makes you think that we are going to be making good decisions here. Still here. I'm not sure where we have known about climate change for 50 years. We haven't, as you said, developed systems to help
*01:10:37*

**Tim Waters**: those who are most impacted we just had another round of talks on that that were not real successful what's different here why are we going to make good decisions well i hope we make good decisions i can't forecast that we will uh what i will say and i'll just add one more thing if you don't is that then overlay the the economic situation situation
*01:11:06*

**Tim Waters**: and now with billionaires getting richer the classes dividing more and more what is there about that that makes you think that the powers that are controlling the this knowledge and power are going to make decisions that are not just good for them but are good for humanity yeah well let me start with the energy
*01:11:36*

**Jason Vallery**: that's a very tractable one. China has done a great job of bringing on renewables. It's been an opportunity for them to build out their grid because it was less mature and they were very quick to do a lot of investment there. I don't think I agree with the assertion that the U.S. is building less renewables. I mean, solar is growing leaps and bounds year over year and it's accelerating how much of it we're deploying. It just doesn't meet the need. It's not enough. You know, and my point earlier holds. I think that we will continue to invest in renewables research.
*01:12:06*

**Jason Vallery**: and it will eventually outpace what we're doing with fossil fuels in the short term. I think about the climate change problem and it's something I care a lot about as well. But when you look at what the science was telling us about climate change and the impact and the degrees of temperature that we would rise based on CO2 in the atmosphere, it was not a this is going to happen next year problem. It's a problem that unfolds over the next century. And so the rationale behind where we sit is
*01:12:37*

**Jason Vallery**: that climate change might take 100 years to have meaningful impact to us, but AI is going to have meaningful impact next year. And so that's why this is taking the front seat over our renewables pledge. And I think that's sound decision making despite the need to ensure we're protecting the environment. Sure. Investing 7% currently
*01:13:06*

**Tim Waters**: If there's 100% of renewable energy coming online right now, the US is putting on 7% of that. China is like 30-something percent. Also, there was something else you just said that, oh, the climate change. We are seeing climate change impact now. We just had the second latest snow ever in the history.
*01:13:37*

**Tim Waters**: the earth here. You know, we are breaking records every single day. People are being impacted. Areas are flooding, fire. You know, that's happening today. And of course, insurance rates are going up today because it's happening today. And so it's not something that's going to happen in 100 years. It's happening today. It happened yesterday. And it's happening
*01:14:06*

**Speaker 6**: Yeah. Yeah. I mean, I don't know the specific stat you're citing, but yeah. Oh, yeah. More than that. Hi. Thank you for speaking. Very, very good speaker. This facility in Texas that needs a lot of energy, and you say it's like a computer? Yeah. Does it not throw off heat? And can that heat be used?
*01:14:36*

**Jason Vallery**: for energy. It doesn't quite work. It's not a closed. It has to dissipate an awful lot of heat. I will point out one of the common challenges to these systems is water use. The industry has solved that problem. These are all closed loop systems that actually don't use any water for cooling. But they do produce a lot of heat that has to be dissipated in the atmosphere. It can't really be recaptured in an effective way today to power the systems. But yeah.
*01:15:06*

**Speaker 6**: Thank you.
*01:15:36*

**Speaker 7**: Hi.
*01:15:43*

**Speaker 7**: Hi.
*01:15:45*

**Speaker 7**: English is not my first language, so please bear me while I try to get my thoughts organized. My question is around the entry points of influence between humans in terms of feedback loop to AI systems and how that relates to governance. Because what I've seen over the last, I don't know, even just since COVID, you know, the more systems are automated, the more you are in some ways, even if you're still talking to a human,
*01:15:46*

**Speaker 7**: and you talk to a human who has less and less capability to make independent decisions because they are limited by what decisions they're able to make and the algorithms that shape that capacity of what is possible. The same thing is true when we navigate websites or when we try to rebook a flight or something on a website and often there's just these interfaces that don't line up. So that's one question in terms of how
*01:16:16*

**Speaker 7**: How does this AI learning, both as opportunity, present maybe a better feedback loop between individuals and their needs and their feedback? And also in terms of larger systems, because the more systems get centrally governed by computer systems or by larger, you know, everybody here knows that if Apple crashes, you know,
*01:16:46*

**Speaker 7**: none of us are going to be able to get anything done. We get more and more dependent on these huge systems that are governed by very central points. And then same thing with the government. If something goes wrong, we all feel it immediately. And our capacity to influence it seems to be reduced more and more the more these systems get more abstract and more complex. So I was just curious if you had any thoughts around the current governance system we have in terms of democracy,
*01:17:16*

**Speaker 7**: in terms of the way we think about controlling businesses that already doesn't seem to be working anymore. This idea that a government can still control businesses. It seems like this interface is breaking down in some way. Yeah, I mean, so there's a few things in there. Let's start with the human circuit breaker. This is what I described in the talk as our opportunity to
*01:17:46*

**Jason Vallery**: to pull the plug or to influence a decision or outcome. You know, these models are not magic. They're just actually a large matrix of floating point numbers. They don't do anything themselves. They have scaffolding around them, code and structures that push inputs in and get inputs out. And so we have the opportunity to construct whatever rules and frameworks and systems of governance over the top of them that we choose to implement.
*01:18:16*

**Jason Vallery**: And so ultimately what we're asking here is as a society what kinds of rules and governance do we want to apply to these systems? And that moves away from being a technical conversation to one of governance and policy. I think this is something that our leaders will need to grapple with and our nation and Congress and president will have to tackle in terms of what kinds of restrictions and what kinds of use cases these are allowed to do and how they must be
*01:18:46*

**Jason Vallery**: It's all possible. It's just a question of do we have the will to put those kinds of restrictions in place? And historically we're not a country that likes to restrict things. We're a country who likes to promote freedom. And when I look at what's happened between us and Europe as a canonical example of what's happening in AI innovation and in technology is that Europe did put a lot of restrictions in place and a lot of rules and
*01:19:17*

**Jason Vallery**: and frameworks, GDPR being a perfect example. And what happened? Innovation stalled out. All the tech companies left. Europe's economy is crumbling. And they all moved here because these companies had the opportunity to innovate. And restrictions and controls stifle innovation, but they also protect us. So we're always balancing ourselves on this fine line of how much governance and how much freedom do we want our society to have.
*01:19:46*

**Jason Vallery**: And that question continues into the AI era and will have to be applied to these systems the same way we've applied it to all technology in our past. I'm optimistic. I think that we are here in this position in this moment time in this nation because of our decisions in this regard in the past. And I am optimistic we'll continue to make the right decisions forward. But we're going to be faced with these decisions, no doubt about it.
*01:20:16*

**Speaker 8**: Jason, you may have answered. Oh, part of the question. I was going to ask a question about regulatory environment. And you started to answer the question just now. But from your perspective, what would be encouraging from your perspective in terms of regulation? And on the other end of that, what would you be most discouraged about? You know, this is a debate that has started and stopped in Congress. We see it in legislators, legislatures across the country.
*01:20:43*

**Speaker 8**: and how that plays out is going to have a huge impact on how this affects all of us. So on a continuum discouraging to encouraging, what would you like to see happen and not happen in terms of regulation? Let me compare and contrast China and the U.S. for a moment. You know, the data that is being generated by all of us, the emails we send, the text messages, all those surveillance cameras I talked about, our phones, all of this gives what's often
*01:21:11*

**Jason Vallery**: is a digital exhaust, a paper trail, a record of who we are. And, you know, I consider that my information. I don't want anyone else to have that. And what's happening right now in China is that has fueled what's called a social credit system. We all have credit scores based on if we pay our bills on time, but in China they're developing a system that takes that digital exhaust and turns it into a score that says, are you a good citizen?
*01:21:41*

**Jason Vallery**: Do you follow our values? Do you show up to work on time and do what you said you were going to do? And it becomes a way that scores you as to if you are a good citizen. And it's being used in ways like dating. Like if you're going out on a date, do I want to actually date this guy? He doesn't, he's not a good person according to his social credit score. That's a terrifying dystopian world I don't want to live in.
*01:22:12*

**Jason Vallery**: The flip side of it is a world where I own my data and I am control of my data. And I think that's the most important question in front of us is what data is allowed to be collected about us and how it's how it can be used. And there's not a clear framework for that today. You know, we're a freedom loving democracy. That social credit system I described, I was reading recently, there was some folks that went in and really surveyed the Chinese population.
*01:22:40*

**Jason Vallery**: They love it there. They think it's the greatest thing. It's taking off like crazy and being used in unique and interesting ways there. But I think it would never fly here. And it terrifies me. And so these are clear, just cultural differences that will come into these frames of governance and be important things that our leaders have to work through. But no time in the past looked like this, where the amount of information you can extract about a human and understand them is crazy. There are countries
*01:23:10*

**Jason Vallery**: right now that are building sovereign AI initiatives for exactly this purpose. The Singaporean government is heavily investing here to take and understand what their citizens are up to. We can't let our government do that. Hi, my name is Elizabeth. I'm the curator of history here at the Longmont Museum. I was wondering if you've read the book Kurt Vonnegut's Player Piano. I have not. It sounds kind of familiar.
*01:23:40*

**Speaker 9**: Anyone in this room had to read this book. I had to read it in high school.
*01:24:11*

**Speaker 9**: Player Piano by Kurt Vonnegut.
*01:24:17*

**Speaker 9**: So it's been about 20 years now since I've had, well, I have read this book in high school.
*01:24:21*

**Speaker 9**: But I think about it all the time whenever we're talking about AI.
*01:24:25*

**Speaker 9**: The title itself gives kind of you an indication of what the book's about, a piano that is played by a machine and not a human.
*01:24:28*

**Speaker 9**: And in this book that was written in the 1960s, basically it's a futuristic, semi-dystopian, yeah, dystopian, world in which the machines can do everything. Only the maybe top 1%, 10% of humans, everyone's ranked by their IQ. Only the highest IQ folks get to have jobs. Everyone else is taken care of by a universal income kind of situation. It might be a comment on communism being in the 60s. But everyone's bored.
*01:24:36*

**Speaker 9**: Everyone's depressed. They have no meaning. I think about this book a lot. Not to give it away, but there is some instance of humans taking on their autonomy in this situation. I highly recommend the book if you haven't read it. It brings up some of these ideas. That is something that I worry about with, okay, so everything gets cheaper, but if we don't have jobs to buy anything,
*01:25:07*

**Jason Vallery**: then I don't know what's the point. Have you seen Westworld? There's a lot of player piano stuff. There's a lot of scenes of self-playing robots playing the piano. That immediately came to mind. But you know I agree like I think all of the risks the one that worries me the most is the crisis of purpose and crisis of meaning and what we do with ourselves in this future. I worry like addiction like that that's you know people are going to turn to chemical happiness for their dopamine fix in a world of depression.
*01:25:36*

**Justin Veach**: and we can just hope that all of those drugs we're inventing solve that too. I thought we were already there actually. Yeah. I think we have maybe time for one or two more questions here. All right I'll try to make this brief. First of all thank you for the talk. I thought it was very digestible. Okay so you may recall about like three years ago there was a Google senior engineer that was fired after saying that Lambda was sentient or something like that.
*01:26:06*

**Speaker 10**: like that. And now I understand that a lot of people can have delusional relationships with, you know, chat GPT and stuff like that. So I don't want to conflate issues necessarily. But with what you were showing with the rise in reasoning that like Gemini has been displaying and stuff like that. How can you be so confident that this does not imply, like if we do reach a super intelligent singularity, how does this not imply sentience?
*01:26:36*

**Jason Vallery**: like from a something that is able to better reason of that than us something that is uh has more access to more information than us and well yeah i'll let you i think the actual question you're asking is philosophical and religious and not technical because really what you're asking is what defines consciousness and is consciousness something that can happen in a computer process um and for that i refer you to your
*01:27:05*

**Jason Vallery**: Church, not me.
*01:27:35*

**Speaker 10**: Well, that's fair.
*01:27:40*

**Speaker 10**: Okay, I'll let other people.
*01:27:43*

**Jason Vallery**: I mean, that's my take on it, honestly, is I don't know. And I think that is one of those, you know, deep philosophical questions underneath all of this that we have to grapple with.
*01:27:45*

**Speaker 11**: I'm so glad that you brought up the singularity and Ray Kurzweil. I feel like I have five years to get all my ducks in a row and stay healthy for five years. 2030 is the big day or the big year. So what do you think? I've listened to the future as closely. Nobody really seems to know what it's going to look like. You know, I feel like right now, are we really there? You said the tidal wave. I think that's a sense of
*01:27:59*

**Speaker 11**: feeling overwhelmed and I kind of try to keep up with this stuff.
*01:28:29*

**Speaker 11**: So what do you think the singularity is going to look like?
*01:28:35*

**Jason Vallery**: Well, I actually don't think it's a single moment in time.
*01:28:39*

**Jason Vallery**: I don't think we're suddenly going to wake up tomorrow and everything will be different.
*01:28:42*

**Jason Vallery**: Like most things, these are gradual changes that we become used to.
*01:28:47*

**Jason Vallery**: And we've been going through it.
*01:28:52*

**Jason Vallery**: Like if we step back a little bit and recognize that we already have cars driving themselves and we have these very super intelligent chatbots that can answer our questions. And if you teleported yourself from five years ago to today, it would be stunned. And I'm pretty sure if we teleported ourselves from today to five years from now, we would be amazed at the progress we've made. But it will just feel like five years to us because these things will unveil themselves day by day, week by week, month by month, and things will continue to get better.
*01:28:54*

**Jason Vallery**: It's the frog in a pot boiling analogy where we're just going to see it starting every day in a different way. I think the day that I'll be most stunned is when I'm sitting in a coffee shop on mainstream and a humanoid robot walks by. That'll be like, oh my goodness, what just happened? That's going to be a transformative moment, but then we'll get used to it. And two weeks later, they'll just be delivering all of our packages from Amazon. Are you going to be first in line for one of those robots? Oh, absolutely.
*01:29:24*

**Jason Vallery**: Yeah, absolutely. And look, they're probably going to suck at first. They'll fall over and there'll be memes because they trip and they'll suck and everybody will point the finger at them. But that's because people don't look at exponential progress and things getting better over time and that it's not always going to be like this. It'll keep getting better. I'm going to have some used third generation robot that I picked up on Craigslist. Yeah, sure. That's what I'm going to have. Yeah, Facebook Marketplace for sure. Yeah, Facebook Marketplace. Yeah.
*01:29:54*

**Justin Veach**: I think your wife Emily has a few words she'd like to say and kind of an invitation
*01:30:23*

**Speaker 12**: too I believe. Hey everybody thanks for being here yeah I'm married to him he condensed
*01:30:30*

**Speaker 12**: probably a decade of dinnertime conversations into this this little so sorry it's a lot it's a lot but we really do talk about this at our house with our kids and
*01:30:40*

**Speaker 12**: they'll vouch like this is what we talk about um and i think that's the real takeaway i i hope
*01:30:53*

**Speaker 12**: you get from this is that we got to start talking about it whether we you know it can become
*01:31:00*

**Speaker 12**: political other issues we have to talk that stuff through so that we can start to impact what it looks like if we're going to have any say
*01:31:06*

**Speaker 12**: It's now. And so we together want to start, are trying to start an initiative. It's Longmont's Next Wave Initiative. And it's really going to just be getting Longmont talking about these things. Some of these great questions coming up, other questions that didn't get to come up. We want to have discussion where everyone can see those questions through and really get to the heart of the matter. So we have some flyers here and then we've got the QR code.
*01:31:18*

**Speaker 12**: I just we're going to have an event of January 15th at Longmont Public Media another discussion 5:30 p.m. if you want to come if you don't want to be part of that I have three asks one could you take the survey and maybe share it with a friend we really want to get a grasp on how where the community is in this conversation already could you also
*01:31:48*

**Speaker 12**: If you haven't tried AI or something, maybe give it a try just to see. Go to openai.com, make an account, and ask it. Like, I've heard you can help people. What can you do for me? I mean, that's how you could start that conversation or help somebody else start one that hasn't. And then maybe talk to a friend or a neighbor and ask them what concerns them about AI and ask them if they use it because we're not talking about
*01:32:18*

**Speaker 12**: it too much. People to people, the conversation sort of shuts down because it's an intimidating conversation to have because of these what's next. You don't want to get too deep, but we're going to have to. So I think that was my asks. Yeah. Sorry to ask anything. I don't like to do that. But yeah. Thank you so much for being here. Thank you, Emily. Thank you guys. Thanks to the audience. I really appreciate all the questions and the participation. And thank you, Jason. Thank you for joining us.
*01:32:48*

**Justin Veach**: Thank you all for coming and being inquisitive and open-minded about this coming AI revolution. I hope we can do this again sometime. I'm down for doing it whenever and we'll do it again in January at LPM if you want to join us. All right. Okay. Thanks for coming. Thanks.
*01:33:18*

**Justin Veach**: Thank you.
*01:34:04*

**Justin Veach**: Thank you.
*01:34:34*

